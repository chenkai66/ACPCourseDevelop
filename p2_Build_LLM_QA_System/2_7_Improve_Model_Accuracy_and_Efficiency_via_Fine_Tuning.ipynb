{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c3b3feff-775c-412d-bc63-39764d9c6f89",
      "metadata": {},
      "source": [
        "# 2.7 Enhancing Model Capabilities through Fine-tuning  ",
        "",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e93f3e3",
      "metadata": {},
      "source": [
        "## üöÑ Preface",
        "",
        "In the previous lessons, we introduced how to build a Q&A bot and attempted to enhance its capabilities by optimizing prompt, constructing RAG chatbot, and extending plugins. However, you may have noticed that you've been \"patching\" around the model‚Äîthese methods essentially enhance the model's performance through external tools, while the model's inherent knowledge boundaries and reasoning abilities remain fundamentally unchanged. This section will take you into the \"internal training ground\" of large language models (LLMs), directly improving the model‚Äôs underlying capabilities through fine-tuning techniques.",
        "",
        "When facing in-depth needs in specific domains, such as precise parsing of elementary school math problems, relying on prompt engineering and RAG chatbot often falls short. For details like operator precedence rules or unit conversion logic in word problems, the model needs to establish a structured knowledge system. This is where fine-tuning shows its unique advantages‚Äîby \"targeted feeding\" the model with math problem-solving examples generated by DeepSeek-R2, you can enable the model to learn DeepSeek-R2's knowledge in mathematics, grasp mathematical thinking paradigms, and even independently discover problem-solving patterns.",
        "",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2783c73",
      "metadata": {},
      "source": [
        "## üçÅ Course Objectives",
        "",
        "After completing this course, you will be able to:",
        "",
        "* Learn and understand the core principles and implementation logic of fine-tuning large language models (LLMs).",
        "* Combine training principles to master the methodology for optimizing key training parameters.",
        "* Independently complete the fine-tuning of models, learn about potential issues that may arise, and practice various solutions.",
        "",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98334953",
      "metadata": {},
      "source": [
        "## 0. Environment Preparation",
        "",
        "Since fine-tuning models requires high hardware performance, you need to use Platform for AI's Data Science Workshop to recreate an instance with a GPU, allowing you to complete the fine-tuning tasks more quickly.<br>",
        "> If you do not have a local GPU environment or your GPU memory is less than 30GB, it is not recommended to take this course locally, as the code may fail to run.",
        "",
        "Please refer to \"[1_0_Computing Environment Preparation](https://edu.aliyun.com/course/3130200/lesson/343310285)\" under `Step 1: Create a PAI DSW Instance` to recreate a new instance, with the following differences:<br>",
        "1. Ensure that the new instance has a **different name** from the previously created instance, such as: acp_gpu<br>",
        "2. For **resource specifications**, select `ecs.gn7i-c8g1.2xlarge` from the free trial tab (this specification includes **one A10 GPU with 30GB of memory**). Rest assured, the free quota you receive will be sufficient to support you in completing **this section of the course** and the **next section on model deployment**.<br>",
        "3. For the **image**, choose `modelscope:1.21.0-pytorch2.4.0-gpu-py310-cu124-ubuntu22.04` (you need to switch the \"Image Configuration\" -> \"Chip Type\" to GPU).<br>",
        "After the instance is successfully created and its status is `Running`, enter the following command in the `Terminal` to obtain the ACP course code:<br>",
        "    ```bash",
        "    git clone https://github.com/AlibabaCloudDocs/aliyun_acp_learning.git",
        "    ```",
        "",
        "Reopen this chapter in the `Notebook` of the newly created GPU instance and continue learning the subsequent content.<br>",
        "",
        "Install the following dependencies:",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "031f61d7",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# The following dependencies need to be installed",
        "%pip install accelerate==1.0.1 rouge-score==0.1.2 nltk==3.9.1 ms-swift[llm]==2.4.2.post2 evalscope==0.5.5rc1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bfaa0e0",
      "metadata": {},
      "source": [
        "## 1. Task Design",
        "",
        "How to solve mathematical problems has always been an important direction in the development of large language models (LLMs), and it just so happens that your intelligent assistant also needs to have basic computational capabilities. To facilitate fine-tuning of the model, you can select a small-parameter open-source model `qwen2.5-1.5b-instruct` as your base model.",
        "",
        "First, you need to download the model and load it into memory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c4f1a505",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-05T03:03:24.966669Z",
          "iopub.status.busy": "2025-03-05T03:03:24.966320Z",
          "iopub.status.idle": "2025-03-05T03:04:13.948625Z",
          "shell.execute_reply": "2025-03-05T03:04:13.948068Z",
          "shell.execute_reply.started": "2025-03-05T03:03:24.966643Z"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading [config.json]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 660/660 [00:00<00:00, 1.15kB/s]\n",
            "Downloading [configuration.json]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.00/2.00 [00:00<00:00, 4.01B/s]\n",
            "Downloading [generation_config.json]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 242/242 [00:00<00:00, 352B/s]\n",
            "Downloading [LICENSE]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.1k/11.1k [00:00<00:00, 19.8kB/s]\n",
            "Downloading [merges.txt]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.59M/1.59M [00:00<00:00, 3.03MB/s]\n",
            "Downloading [model.safetensors]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.88G/2.88G [00:10<00:00, 295MB/s]\n",
            "Downloading [README.md]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.80k/4.80k [00:00<00:00, 9.70kB/s]\n",
            "Downloading [tokenizer.json]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.71M/6.71M [00:00<00:00, 7.72MB/s]\n",
            "Downloading [tokenizer_config.json]: 100%|‚ñà| 7.13k/7.13k [00:01<00:00, 4.46kB/s]\n",
            "Downloading [vocab.json]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.65M/2.65M [00:00<00:00, 2.99MB/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO:swift] Loading the model using model_dir: ./model\n",
            "[INFO:swift] model_kwargs: {'device_map': 'cpu'}\n",
            "[INFO:swift] model.max_model_len: 32768\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ê®°ÂûãÂàùÂßãÂåñÂÆåÊàê\n"
          ]
        }
      ],
      "source": [
        "# Download model parameters to the ./model directory",
        "!mkdir ./model",
        "!modelscope download --model qwen/Qwen2.5-1.5B-Instruct --local_dir './model'",
        "",
        "from swift.llm import (",
        "    get_model_tokenizer, get_template, ModelType,",
        "    get_default_template_type",
        ")",
        "import torch",
        "",
        "# You can modify the query (model input) according to your needs",
        "",
        "# Obtain model information",
        "model_type = ModelType.qwen2_5_1_5b_instruct",
        "template_type = get_default_template_type(model_type)",
        "# Set the local model location",
        "model_id_or_path = \"./model\"",
        "# Initialize the model and input/output formatting template",
        "kwargs = {}",
        "model, tokenizer = get_model_tokenizer(model_type, torch.float32, model_id_or_path=model_id_or_path, model_kwargs={'device_map': 'cpu'}, **kwargs)",
        "model.generation_config.max_new_tokens = 128",
        "template = get_template(template_type, tokenizer, default_system='')",
        "print(\"Model initialization completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1063c961",
      "metadata": {},
      "source": [
        "You can directly try its effect on math problems (the answer is: 648 kilograms of radishes can be harvested):  ",
        "",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d446abd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-05T03:04:22.515786Z",
          "iopub.status.busy": "2025-03-05T03:04:22.515413Z",
          "iopub.status.idle": "2025-03-05T03:04:39.969526Z",
          "shell.execute_reply": "2025-03-05T03:04:39.969036Z",
          "shell.execute_reply.started": "2025-03-05T03:04:22.515762Z"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Âú®‰∏ÄÂùóÂ∫ïËæπÈïø18Á±≥ÔºåÈ´ò6Á±≥ÁöÑ‰∏âËßíÂΩ¢ËèúÂú∞ÈáåÁßçËêùÂçúÔºéÂ¶ÇÊûúÊØèÂπ≥ÊñπÁ±≥Êî∂ËêùÂçú12ÂçÉÂÖãÔºåËøôÂùóÂú∞ÂèØÊî∂ËêùÂçúÂ§öÂ∞ëÂçÉÂÖãÔºü\n",
            "Ê≠£Á°ÆÁ≠îÊ°àÊòØÔºöÂèØÊî∂ËêùÂçú648ÂçÉÂÖã\n",
            "-----------Â§ßÊ®°ÂûãÂõûÁ≠î-------------\n"
          ]
        },
        {
          "data": {
            "text/latex": [
              "Ë¶ÅËÆ°ÁÆóËøôÂùóÂú∞ÂèØ‰ª•Êî∂Ëé∑ÁöÑËêùÂçúÊÄªÈáèÔºåÊàë‰ª¨È¶ñÂÖàÈúÄË¶ÅËÆ°ÁÆóÂá∫Ëøô‰∏™‰∏âËßíÂΩ¢ËèúÂú∞ÁöÑÈù¢ÁßØ„ÄÇ‰∏âËßíÂΩ¢ÁöÑÈù¢ÁßØÂÖ¨ÂºèÊòØÔºö\n",
              "\n",
              "\\[ \\text{Èù¢ÁßØ} = \\frac{1}{2} \\times \\text{Â∫ïËæπÈïøÂ∫¶} \\times \\text{È´ò} \\]\n",
              "\n",
              "Ê†πÊçÆÈ¢òÁõÆÁªôÂá∫ÁöÑÊï∞ÊçÆÔºåÂ∫ïËæπÈïøÂ∫¶‰∏∫18Á±≥ÔºåÈ´ò‰∏∫6Á±≥Ôºå‰ª£ÂÖ•‰∏äËø∞ÂÖ¨ÂºèÂæóÂà∞Ôºö\n",
              "\n",
              "\\[ \\text{Èù¢ÁßØ} = \\frac{1}{2} \\times 18 \\times 6 = 9 \\times 6 = 54 \\, \\text{Âπ≥ÊñπÁ±≥} \\"
            ],
            "text/plain": [
              "<IPython.core.display.Latex object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------ÂõûÁ≠îÁªìÊùü--------------\n"
          ]
        }
      ],
      "source": [
        "from swift.llm import inference",
        "from IPython.display import Latex, display",
        "",
        "math_question = \"In a triangular vegetable field with a base of 18 meters and a height of 6 meters, radishes are planted. If 12 kilograms of radishes are harvested per square meter, how many kilograms of radishes can be harvested from this field?\"",
        "query = math_question",
        "response, _ = inference(model, template, query)",
        "print(query)",
        "print(\"The correct answer is: 648 kilograms of radishes can be harvested\")",
        "print('-----------Large model response-------------')",
        "display(Latex(response)) ",
        "print('------------End of response--------------')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec0f6e2d",
      "metadata": {},
      "source": [
        "It can be observed that your model does not seem to be able to accurately compute this simple mathematical problem. The model knows the formula for the area of a triangle but fails to use this knowledge to accurately calculate the weight of the radish.",
        "",
        "Of course, the effect of using RAG is the same. From previous learning, you know that RAG is more like an open-book exam. However, you have never seen an open-book math exam improve scores because the core of improving math ability lies in enhancing students' logical reasoning and computational skills rather than knowledge retrieval.",
        "",
        "Therefore, to directly enhance the ability of your Q&A bot on simple mathematical problems, you must use model fine-tuning to improve the model‚Äôs logical reasoning ability. (Computational ability can be enhanced by introducing a \"calculator\" plugin.)  ",
        "",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dc8d595",
      "metadata": {},
      "source": [
        "## 2. Fine-tuning Principles",
        "",
        "### 2.1 How Models Learn",
        "",
        "#### 2.1.1 Machine Learning - Finding Patterns Through Data",
        "",
        "In traditional programming work, you usually know the explicit rules and write these rules into functions, such as: $f(x) = ax$.",
        "",
        "Here, a is a known deterministic value (also called a parameter or weight). This function represents a simple algorithmic model that can compute (predict) the output $y$ based on the input $x$.",
        "",
        "However, in real-world scenarios, it's more likely that you don't know the explicit rules (parameters) beforehand but may have some observed phenomena (data).",
        "",
        "The goal of machine learning is to help you use this data (training set) to try and find (learn) these parameter values, a process known as training the model.",
        "",
        "#### 2.1.2 loss function & Cost Function - Quantifying Model Performance",
        "",
        "To find the most suitable parameters, you need a way to measure whether the currently tested parameters are appropriate.",
        "",
        "For better understanding, assume you now need to evaluate whether the parameter a in the model $f(x) = ax$ is suitable.",
        "",
        "##### loss function",
        "",
        "You can assess the model's performance on a single data point $x_i, y_i$ by subtracting the predicted result $f(x_i)$ from the actual result $y_i$ for each sample $x_i$ in the training set. The function used to evaluate this error is called the loss function (or error function): $L(y_i, f(x_i)) = y_i - ax_i$.",
        "",
        "Directly calculating the difference might yield positive or negative values, which could cancel each other out when aggregating losses, underestimating the total loss. To address this issue, you can consider squaring the difference as the loss: $L(y_i, f(x_i)) = (y_i - ax_i)^2$. Additionally, squaring amplifies the impact of errors, helping you identify the most suitable model parameters.",
        "",
        "> In practical applications, different models may use different calculation methods as the loss function.",
        "",
        "##### Cost Function",
        "",
        "To evaluate the model's overall performance across the entire training set, you can calculate the average loss of all samples (i.e., mean squared error). This function, used to assess the model's overall performance across all training samples, is called the Cost Function (or cost function).",
        "",
        "For a training set with m samples, the cost function can be expressed as: $J(a) = \\frac{1}{m} \\sum_{i=1}^{m} (y_i - ax_i)^2$.",
        "",
        "> In practical applications, different models may also choose different calculation methods as the Cost Function.",
        "",
        "With the Cost Function, the task of finding suitable model parameters can be equated to finding the minimum value of the Cost Function (i.e., the optimal solution). Finding the minimum value of the Cost Function means that the corresponding parameter a value is the most suitable model parameter value.",
        "",
        "If you plot the Cost Function, the task of finding the optimal solution essentially involves finding the lowest point on the curve or surface.",
        "<div style=\"text-align: center\">",
        "<img src=\"https://img.alicdn.com/imgextra/i4/O1CN0149XTTS1WUKSTtpeoh_!!6000000002791-2-tps-2314-1682.png\" style=\"width: 400px; display: block; margin-left: auto; margin-right: auto\"/>",
        "</div>",
        "",
        "> In real projects, people often interchangeably use the terms cost function and loss function. In subsequent content and code, we will follow this engineering convention and refer to the cost function as the loss function (loss function).",
        "",
        "#### 2.1.3 Gradient Descent Algorithm - Automatically Finding the Optimal Solution",
        "",
        "In the previous curve, you can visually identify the lowest point. However, in practical applications, models typically have many parameters, and their Cost Functions are often complex surfaces in high-dimensional spaces, making it impossible to find the optimal solution through direct observation. Therefore, you need an automated method to find the optimal parameter configuration.",
        "",
        "Gradient descent is one of the most common methods. A typical implementation of gradient descent starts by randomly selecting a starting point on the surface (or curve), then continuously making small adjustments to the parameters until the lowest point (corresponding to the optimal parameter configuration) is found.",
        "",
        "<div style=\"text-align: center\">",
        "<img src=\"https://img.alicdn.com/imgextra/i2/O1CN01ihhR9Y1IbkFZTQ3bV_!!6000000000912-1-tps-1080-810.gif\" style=\"width: 400px;margin-left: auto; margin-right: auto\"/>",
        "<img src=\"https://img.alicdn.com/imgextra/i3/O1CN01meUISA1dHgq2mqm6V_!!6000000003711-1-tps-1080-810.gif\" style=\"width: 400px;margin-left: auto; margin-right: auto\"/>",
        "</div>",
        "",
        "When training a model, you need the training program to automatically adjust the parameters so that the value of the Cost Function approaches the lowest point. Therefore, the gradient descent algorithm must automatically control two aspects: the direction of parameter adjustment and the magnitude of parameter adjustment.",
        "",
        "##### Direction of Parameter Adjustment",
        "",
        "If the Cost Function is a U-shaped curve, you can intuitively see that the parameter adjustment should move in the direction where the absolute value of the slope decreases, i.e., towards a flatter area.",
        "<div style=\"text-align: center\">",
        "<img src=\"https://img.alicdn.com/imgextra/i2/O1CN01ME3u6G203FVsQsmLe_!!6000000006793-2-tps-1608-1244.png\" style=\"width: 400px; display: block; margin-left: auto; margin-right: auto\"/>",
        "</div>",
        "",
        "If the Cost Function is a surface in a three-dimensional coordinate system, the direction of parameter adjustment should similarly move towards flatter areas. However, at a certain point on the surface, there are multiple possible descending directions. To find the lowest point as quickly as possible, you should move in the steepest direction.",
        "<div style=\"text-align: center\">",
        "<img src=\"https://img.alicdn.com/imgextra/i2/O1CN01Uh8OxI1mqnkBHqMjH_!!6000000005006-1-tps-664-684.gif\" style=\"width: 400px; display: block; margin-left: auto; margin-right: auto\"/>",
        "</div>",
        "",
        "In mathematics, the gradient points in the direction of the steepest ascent from a point on the surface, and its opposite direction is the steepest descent.",
        "",
        "To find the lowest point on the surface in the shortest time, the direction of parameter adjustment should be along the opposite direction of the gradient, i.e., the green arrow direction in the two figures above.",
        "",
        "> For a curve f(a) in a two-dimensional coordinate system, the gradient at a point is the slope at that point. ",
        "> For a surface f(a,b) in a three-dimensional coordinate system, the gradient at a point is a two-dimensional vector composed of the slope values in the a and b axis directions. This indicates the rate of change of the function in each input variable direction and points in the direction of the fastest growth. Calculating the slope of a point on the surface in a particular axis direction is also referred to as taking the partial derivative.",
        "",
        "##### Magnitude of Parameter Adjustment",
        "",
        "After determining the direction of parameter adjustment, the magnitude of the adjustment needs to be determined.",
        "",
        "Adjusting parameters with a fixed step size is the easiest approach, but this may prevent you from ever finding the lowest point, causing oscillation near the lowest point instead.",
        "",
        "For example, in the figure below, adjusting parameters with a fixed step size of 1.5 results in oscillation around the lowest value, unable to further approach the lowest point.",
        "",
        "<div style=\"text-align: center\">",
        "<img src=\"https://img.alicdn.com/imgextra/i3/O1CN01y7FatQ27bKI9CYCJ1_!!6000000007815-1-tps-938-646.gif\" style=\"width: 400px; display: block; margin-left: auto; margin-right: auto\"/>",
        "</div>",
        "",
        "To avoid this issue, the adjustment magnitude should be reduced as you approach the lowest point. The closer you get to the lowest point, the smaller the slope becomes. Therefore, instead of using a fixed step size, you can use the slope at the current position as the adjustment magnitude.",
        "",
        "<div style=\"text-align: center\">",
        "<img src=\"https://img.alicdn.com/imgextra/i3/O1CN01h45Ifb1xRZhXXIXEC_!!6000000006440-1-tps-892-618.gif\" style=\"width: 400px; display: block; margin-left: auto; margin-right: auto\"/>",
        "</div>",
        "",
        "However, some Cost Function curves are very steep, and directly using the slope may still cause oscillation around the lowest point. To address this, you can multiply the slope by a coefficient to regulate the step size. This coefficient is called the learning rate.",
        "",
        "The choice of learning rate is particularly important for training effectiveness and efficiency:",
        "",
        "<div style=\"display: flex; justify-content: space-between; gap: 2px; padding: 15px; background:rgba(0,0,0,0)\">",
        "    <!-- Column 1 -->",
        "    <div style=\"flex: 1; padding: 10px; border: 1px solid #ddd; border-radius: 5px\">",
        "        <p style=\"margin-top: 10px\">An appropriate learning rate allows you to find suitable parameters in a relatively short time.</p>",
        "        <img src=\"https://img.alicdn.com/imgextra/i3/O1CN01NrvVfj1sCqtKHLyia_!!6000000005731-2-tps-1680-1224.png\" style=\"width: 100%; height: auto; border-radius: 3px\"/>",
        "    </div>",
        "    <!-- Column 2 -->",
        "    <div style=\"flex: 1; padding: 10px; border: 1px solid #ddd; border-radius: 5px\">",
        "        <p style=\"margin-bottom: 10px\">An excessively low learning rate, while capable of finding suitable parameters, leads to greater time and resource consumption.</p>",
        "        <img src=\"https://img.alicdn.com/imgextra/i1/O1CN015dbcz61MCn8LkN2Ta_!!6000000001399-2-tps-1728-1300.png\" style=\"width: 100%; height: auto; border-radius: 3px\"/>",
        "    </div>",
        "    <!-- Column 3 -->",
        "    <div style=\"flex: 1; padding: 10px; border: 1px solid #ddd; border-radius: 5px\">",
        "        <p style=\"margin-bottom: 10px\">An excessively high learning rate may cause you to skip the optimal solution, ultimately failing to find the lowest point.</p>",
        "    </div>",
        "</div>",
        "",
        "<img src=\"https://img.alicdn.com/imgextra/i1/O1CN01l4leTB1LKI0BcVs16_!!6000000001280-2-tps-1658-1262.png\" style=\"width: 100%; height: auto; border-radius: 3px\"/>",
        "    </div>",
        "</div>",
        "",
        "A smaller learning rate, although it will consume a lot of computational resources and time, actually helps you approach the lowest point more closely. In practical model training engineering, attempts are also made to dynamically adjust the learning rate. For example, in Model Studio's model fine-tuning feature, there is a [learning rate adjustment strategy](https://help.aliyun.com/zh/model-studio/user-guide/using-fine-tuning-on-console#7864d6a606ztg), which allows you to configure linear decay of the learning rate or decay according to a curve. Alibaba Cloud's PAI also provides an [AutoML](https://help.aliyun.com/zh/pai/user-guide/automl/) tool that can help you automatically find a more suitable learning rate.",
        "",
        "#### 2.1.4 More parameters used in model training engineering",
        "",
        "##### batch size",
        "",
        "In the process of finding the lowest point of the Cost Function, each calculation of the gradient (the slope in each direction) and then updating the model parameters based on that gradient, preparing for the next calculation and update, is called a training step.",
        "",
        "In previous introductions, each training step calculates the gradient at a certain point and then updates the parameters. You can also set the batch size to n, averaging the gradients based on n samples (mini-batch) to update the parameters.",
        "",
        "A larger batch size can accelerate the training process, but it will also consume more resources, and an excessively large batch size may lead to issues such as reduced model generalization performance.",
        "",
        "Choosing an appropriate batch size is a balancing act, depending on available hardware resources, training time, and desired model performance. In practice, experiments are often needed to determine the most suitable batch size for a specific task.",
        "",
        "##### eval steps",
        "",
        "Because the training set is usually very large, people typically do not use the validation set for evaluation after a full iteration over the training set. Instead, they choose to evaluate using the validation set after a certain number of training steps. This interval is usually controlled by the eval_steps parameter.",
        "",
        "##### epoch",
        "",
        "A complete iteration over the training set is called an epoch. In actual training, you cannot guarantee finding the optimal solution (lowest point) of the Cost Function within one epoch. Therefore, many training frameworks support configuring the number of training epochs, such as the num_train_epochs parameter provided in the swift training framework.",
        "",
        "A too small epoch value may result in not finding the optimal model parameters by the end of training. A too large epoch value can lead to excessively long training times and resource waste.",
        "",
        "A common method for finding a suitable epoch is early stopping: before starting training, you do not preset an epoch value (or set a larger value). During training, you periodically evaluate the model's performance using the validation set. When the model's performance on the validation set no longer improves (or starts to decline), training is automatically stopped.",
        "",
        "Of course, early stopping is not the only solution. There are many other methods in the industry to determine a suitable epoch value, such as dynamically adjusting the learning rate based on changes in validation set loss to indirectly affect the number of training epochs.",
        "",
        "#### 2.1.5 Neural Network - Universal Complex Function Approximator",
        "",
        "**Problems faced in machine learning:**",
        "",
        "In text generation tasks, the input $x$ and output $y$ generally have very high dimensions, making it impossible to directly discern the underlying patterns. What should you do?",
        "",
        "Smart mathematicians found a **universal function approximator ‚Äî neural network (multi-layer)**, which has become the foundation of current complex machine learning tasks.",
        "",
        "<div style=\"text-align: center\">",
        "<img src=\"https://img.alicdn.com/imgextra/i1/O1CN01QRD5MH1rwMdJHBzxi_!!6000000005695-2-tps-1080-533.png\" style=\"width: 400px; display: block; margin-left: auto; margin-right: auto\"/>",
        "</div>",
        "",
        "One layer of a neural network is generally expressed as $Y=œÉ(W‚ãÖX)$, where the uppercase input $X$ and output $Y$ indicate they are multi-dimensional, $œÉ$ is the activation function, and $W$ represents the parameters of the assumed function $f$. A k-layer neural network can be expressed as $Y=œÉ(W_k ‚ãØ œÉ(W_2 ‚ãÖœÉ(W_1‚ãÖX)))$.",
        "",
        "The activation function is a key component in neural networks that introduces non-linear transformations and determines whether neurons are activated and transmit information. For example, the most commonly used activation function RELU can be written as:",
        "",
        "**$RELU(input) = max( 0, input)= \\begin{cases} input & \\text{if } input > 0 \\\\ 0 & \\text{if } input ‚â§ 0 \\end{cases}$**",
        "",
        "When $input‚â§0$, the neuron is not activated; when $input>0$, the neuron is activated and begins transmitting information to the output.",
        "",
        "Expanding one layer of a neural network can be written as follows (assuming $X$ is a $3√ó2$ dimensional matrix and $Y$ is a $2√ó2$ dimensional matrix):",
        "",
        "$œÉ(W_{2√ó3}‚ãÖX_{3√ó2})= œÉ(\\left[ \\begin{matrix} w_{1,1} & w_{1,2} & w_{1,3} \\\\ w_{2,1} & w_{2,2} & w_{2,3} \\end{matrix} \\right]√ó\\left[ \\begin{matrix} x_{1,1}& x_{1,2}\\\\ x_{2,1}& x_{2,2} \\\\ x_{3,1}& x_{3,2} \\end{matrix} \\right])$",
        "",
        "$= œÉ(\\left[\\begin{matrix}",
        "w_{1,1}√óx_{1,1}+w_{1,2}√óx_{2,1}+w_{1,3}√óx_{3,1}&",
        "w_{1,1}√óx_{1,2}+ w_{1,2}√óx_{2,2}+w_{1,3}√óx_{3,2} \\\\",
        "w_{2,1}√óx_{1,1}+ w_{1,2}√óx_{2,1}+w_{1,3}√óx_{3,1}&",
        "w_{2,1}√óx_{1,2}+ w_{2,2}√óx_{2,2}+w_{2,3}√óx_{3,2} \\end{matrix} \\right])$",
        "",
        "$= \\left[ \\begin{matrix} max(0, \\sum\\limits_{k=1}^{3}w_{1,k}√óx_{k,1})& max(0, \\sum\\limits_{k=1}^{3}w_{1,k}√óx_{k,2})\\\\ max(0, \\sum\\limits_{k=1}^{3}w_{2,k}√óx_{k,1})& max(0, \\sum\\limits_{k=1}^{3}w_{2,k}√óx_{k,2}) \\end{matrix} \\right]= \\left[ \\begin{matrix} y_{1,1}& y_{1,2}\\\\ y_{2,1}& y_{2,2} \\end{matrix} \\right]=Y_{2√ó2}$",
        "",
        "Fortunately, the gradient descent method remains effective on high-dimensional, complex functions.",
        "",
        "<div style=\"text-align: center\">",
        "<img src=\"https://img.alicdn.com/imgextra/i3/O1CN011caxP31GiUrEv1aGH_!!6000000000656-2-tps-847-779.png\" style=\"width: 400px; display: block; margin-left: auto; margin-right: auto\"/>",
        "</div>",
        "",
        "Now you have the ace combination:",
        "",
        "**A tool capable of approximating any complex function ‚Äî neural network + a method capable of fitting data patterns and learning function parameters ‚Äî gradient descent method**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "576f0801",
      "metadata": {},
      "source": [
        "### 2.2 Efficient Fine-Tuning Techniques",
        "",
        "#### 2.2.1 Pre-training and Fine-Tuning",
        "",
        "Through previous learning, you have already understood the essence of model training, which is to find the most suitable combination of parameters.",
        "",
        "The model you initially downloaded is a pre-trained set of parameters.",
        "",
        "Fine-tuning involves further training and adjusting these parameters to adapt to your target task (e.g., solving math problems here).",
        "",
        "Next, taking `qwen2.5-1.5b-instruct` as an example, let's roughly examine the time and hardware requirements for training a model from scratch.",
        "",
        "GPU memory requirements:",
        "",
        "*   Memory occupied by 1.5B parameters (assuming full precision FP32, with each parameter occupying 4 bytes): $1.5*{10^9}*4/{2^{30}}‚âà 5.59GB$",
        "    ",
        "*   Generally, when training a model, it requires about 7 to 8 times the memory of the model parameters, i.e., approximately **45GB** of GPU memory. This memory requirement basically exceeds the configuration of most graphics cards and surpasses the memory of your GPU experimental environment.",
        "    ",
        "<br/>",
        "Training time estimation:",
        "",
        "*   Example calculation: $Total training tokens = 200B (approximately 300,000 volumes of Dream of the Red Mansions)$, $Batch size (8 GPUs in parallel) = 2k tokens$, $Tokens per second = 150 tokens/GPU √ó 8 GPUs = 1200 tokens/s$",
        "    ",
        "*   Training time (days) = $\\frac{Total Tokens}{Batch size * Tokens per second * 86400}‚âà10 days$",
        "    ",
        "*   Actual situation: Consider data preprocessing, checkpoint saving, distributed communication overhead; actual time may be extended by **20-50%**. If the data volume is larger (e.g., 1T tokens), the time could reach **several months**.",
        "    ",
        "<br/>",
        "Training cost:",
        "",
        "*   For short-term training (10 days), compared to a one-time investment in purchasing hardware, it is more recommended to use cloud services on a pay-per-use basis to effectively save training costs.",
        "    ",
        "*   Training cost = GPU server unit price * training time",
        "    ",
        "<br/>",
        "",
        "In summary, **reducing server unit price** and **shortening training time** can effectively reduce training costs, where **reducing memory requirements** can effectively lower server unit price, and reducing **total training data volume** can shorten training time.",
        "",
        "<br/>",
        "",
        "In the actual model training process, there is also a challenge: **the high cost of obtaining labeled data**, **especially for specific tasks** (e.g., medical image analysis or niche language processing). You can try step-by-step training of the model through \"pre-training\" and \"fine-tuning\", where:",
        "",
        "*   **Pre-training**: Training the model on a large-scale **general dataset** so that it can learn broad foundational knowledge or feature representations. This knowledge is usually general and not aimed at any specific task. Pre-training is not task-specific but provides a powerful initial model for various downstream tasks. Typical pre-trained models: Qwen2.5-Max, DeepSeek-V3, GPT-4, etc.",
        "    ",
        "*   **Fine-tuning**: Further training the model using a **small-scale dataset** specific to a task based on the pre-trained model. The goal is to make the model adapt to specific downstream tasks (e.g., medical, legal, and other professional domain needs).",
        "    ",
        "",
        "The table below shows the main differences between pre-training and fine-tuning:",
        "",
        "<div style=\"width: 20%\">",
        "    ",
        "|  **Feature**  |  **Pre-training**  |  **Fine-tuning**  |",
        "| --- | --- | --- |",
        "|  Objective  |  $ $ Learning general features  |  Adapting to specific tasks  |",
        "|  Data  |  Large-scale general data  |  Small-scale task-related data  |",
        "|  Training method  |  Self-supervised/Unsupervised  |  Supervised  |",
        "|  Parameter updates  |  All parameters trainable  |  Partial or all parameters trainable  |",
        "|  Application scenarios  |  Base model construction  |  Specific task optimization  |",
        "",
        "</div>",
        "",
        "It is worth mentioning that **pre-training generally learns through self-supervised learning**, with data coming from massive texts on the internet (e.g., Wikipedia, books, web pages), allowing the model to find patterns or \"guess answers\" on its own. This learning method does not require manual annotation, saving a lot of labor costs, making it naturally suitable for learning from massive data.",
        "",
        "On the other hand, **fine-tuning is done through supervised learning**, requiring small-scale annotated data for specific tasks (e.g., annotated reviews for sentiment classification, annotated medical texts), and directly teaching the model to complete tasks using annotated data. Due to the high cost of manual annotation, this learning method is difficult to scale to massive data, thus being more suitable for model training with clear scenario goals, typically requiring only a few thousand to tens of thousands of samples.",
        "",
        "Therefore, you can quickly and cost-effectively build your large model application in the following ways:",
        "",
        "Step 1: Directly choose a pre-trained model (e.g., Qwen, DeepSeek, GPT), which can save the comprehensive cost of training a model from scratch.",
        "",
        "Step 2: Fine-tune the model according to your actual scenario, usually only needing to build a few thousand annotated data applicable to the actual scenario, because the total number of training tokens is greatly reduced, effectively shortening the training time, thereby further reducing the training cost.",
        "",
        "Fine-tuning can shorten training time, but can fine-tuning the model also reduce memory requirements?",
        "",
        "The number of model parameters is the main reason affecting memory requirements. From the perspective of adjusting the size of the parameter count, fine-tuning can be divided into **full-parameter fine-tuning** and **parameter-efficient fine-tuning**.",
        "",
        "**Full-parameter fine-tuning (Full Fine Tuning)** is a model optimization method that fine-tunes all parameters based on the pre-trained model, meaning that in the above model structure, any parameter will be adjusted. This method avoids consuming the large amount of computational resources required to retrain all parameters of the model from scratch while avoiding performance degradation due to some parameters not being fine-tuned. However, large model training costs are high, requiring substantial computational resources and large amounts of data. Even with full-parameter fine-tuning, high training costs are often still needed.",
        "",
        "**Efficient fine-tuning techniques (PEFT)** significantly reduce the computational cost of large model fine-tuning by adjusting a small number of parameters while maintaining performance close to full-parameter training. Typical methods include Adapter Tuning, Prompt Tuning, and LoRA. Among them, LoRA, which only needs to train small parameter matrices (i.e., low-rank matrices, requiring only 0.1%-1% of the original model's parameters), has become the preferred solution for resource-constrained scenarios. The following focuses on how LoRA achieves parameter-efficient fine-tuning with extremely low parameter counts.",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f59f270",
      "metadata": {},
      "source": [
        "#### 2.2.2 LoRA Fine-tuning",
        "",
        "LoRA (Low-Rank Adaptation (LoRA) (LoRA)) fine-tuning is currently the most commonly used fine-tuning method. It does not concern itself with the architecture of the model but abstracts and decomposes the parameters that need to be updated during fine-tuning into two much smaller low-rank matrices $A_{d√ór}$ and $B_{r√ód}$ for training, while the original matrix of the model remains untrained, i.e., $W^{fine-tuning}_{d√ód} = fine-tuning(A_{d√ór}‚ãÖB_{r√ód}) + unchanged(W^{pre-fine-tuning}_{d√ód})$.",
        "",
        "If you still don't fully understand the process of low-rank decomposition, let's go back to the expression of a neural network and label the dimensions of each vector and matrix. Suppose the input $X$ is a 5-dimensional vector and the output $Y$ is a 4-dimensional vector, then $W$ is a $5√ó4$ matrix, written as $W‚ààR^{5√ó4}$, containing 20 parameters in total.",
        "",
        "A single-layer neural network can be expressed as: $Y_{5√ó1}=œÉ(W_{5√ó4}‚ãÖX_{4√ó1})$.",
        "",
        "The rank of a matrix can be understood more simply as representing its effective information content. For example, although this low-rank matrix has two rows and three columns, it can actually be represented by one row (column) vector for the other rows (columns), so its rank is 1.",
        "",
        "$rank(left[ \begin{matrix} 1& 2&3 \\ 2& 4&6 \\ end{matrix} \right] )=1$",
        "",
        "**In model fine-tuning, it can be assumed that most of the information updates (high-rank) are completed during pre-training, and the effective information brought by fine-tuning is minimal (low-rank).** The formula can be written as:",
        "",
        "$W_{5√ó4}^{pre-training} -W_{5√ó4}^{initial}=ŒîW_{5√ó4}^{pre-training}, rank(ŒîW_{5√ó4}^{pre-training})= 5$, whereas $W_{5√ó4}^{fine-tuning} -W_{5√ó4}^{pre-training}=ŒîW_{5√ó4}^{fine-tuning}, rank(ŒîW_{5√ó4}^{fine-tuning})‚â§2$.",
        "",
        "Because low-rank matrices have low information density, they can be decomposed via low-rank decomposition to extract the effective information into two much smaller matrices. Here, assuming $rank(ŒîW_{5√ó4}^{fine-tuning})=1$:",
        "",
        "$ŒîW_{5√ó4}^{fine-tuning}=left[ \begin{matrix} 1 & 0 & 2 & -1\\ 2& 0&4& -2 \\\\ 3& 0&6& -3 \\\\ 4& 0&8 & -4\\\\ 5& 0&10 & -5\\\\ end{matrix} \right]_{5√ó4}=left[ \begin{matrix} 1\\\\ 2\\\\ 3\\\\ 4\\\\ 5\\\\ end{matrix} \right]_{5√ó1}√ó left[ \begin{matrix} 1& 0 & 2 & -1 \\\\ end{matrix} \right]_{1√ó4}$",
        "",
        "Based on the above learning outcomes, taking the base model `qwen2.5-1.5b-instruct` as an example, assuming $8=r<<d=1024$, let‚Äôs compare the actual number of parameters.",
        "",
        "$W^{fine-tuning}_{d√ód} = fine-tuning(A_{d√ór}*B_{r√ód}) + unchanged(W^{pre-fine-tuning}_{d√ód})$",
        "",
        "<div style=\"width: 40%\">",
        "",
        "| **Method** | **Parameter Calculation Formula** | **Number of Parameters** | **Savings Ratio** |",
        "| --- | --- | --- | --- |",
        "| Full-parameter fine-tuning | $W_{d√ód}$, 1024 √ó1024 | 1,048,576 | $0\\%$ |",
        "| LoRA fine-tuning | $A_{d√ór}$ and $B_{r√ód}$, 1024√ó8 + 8 √ó1024 | 16,384 | $98.44 \\%$ |",
        "",
        "</div>",
        "",
        "Finally, during inference, combine $A_{d√ór}, B_{r√ód}, W^{pre-fine-tuning}_{d√ód}$, optionally pre-generate or dynamically generate $W^{fine-tuning}_{d√ód}$.",
        "",
        "<div style=\"text-align: center;\">",
        "<a href=\"https://img.alicdn.com/imgextra/i2/O1CN014UROTc25B6NgTnWtZ_!!6000000007487-2-tps-3734-1286.png\" target=\"_blank\">",
        "<img src=\"https://img.alicdn.com/imgextra/i2/O1CN014UROTc25B6NgTnWtZ_!!6000000007487-2-tps-3734-1286.png\" style=\"width: 700px;background:white;display: block; margin-left: auto; margin-right: auto\"/>",
        "</a>",
        "</div>",
        "",
        "When fine-tuning using LoRA, the main adjustable parameter is our assumed low-rank $r$. The larger it is preset, the more capable it is of capturing more complex feature changes, but the harder it is to fine-tune the model, requiring more memory and training epochs.",
        "",
        "Empirically, the rank $r$ is closely related to the amount of training data:",
        "",
        "For small training sets (1k-10k samples): It is recommended that rank $r‚â§16$ to avoid too many training epochs, which could lead the model to memorize the training set rather than learn the features within it.",
        "",
        "For large training sets (100k+ samples): You can try rank $r‚â•32$, which can fully explore potential patterns in the data.",
        "",
        "#### 2.2.3 LoRA Fine-tuning Effectiveness",
        "",
        "The authors of LoRA compared various fine-tuning methods across two datasets (the x-axis represents the number of trainable parameters, and the y-axis shows the effectiveness of training). It can be seen that LoRA fine-tuning offers the best cost-effectiveness.",
        "",
        "<div style=\"text-align: center;\">",
        "<img src=\"https://img.alicdn.com/imgextra/i1/O1CN01RGquUv1ZlDuoik8zU_!!6000000003234-2-tps-1944-662.png\" style=\"width: 700px;background:white;display: block; margin-left: auto; margin-right: auto\"/>",
        "</div>",
        "It is evident that not all methods benefit from having more trainable parameters; **more training parameters do not necessarily mean better results.** However, **the LoRA method demonstrates better scalability and task performance.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1204e108",
      "metadata": {},
      "source": [
        "## 3. Fine-Tuning Practice",
        "",
        "### 3.1 Model Training Status and Metrics",
        "",
        "Training a model is very similar to the human learning and exam process.",
        "",
        "A model must undergo the test of three sets of questions, generating two metrics to determine the state of model training. These are:",
        "",
        "Three sets of questions:",
        "",
        "*   **Training set**: The practice workbook with detailed answer explanations. The model will repeatedly practice and generate **training loss** based on the loss function. The smaller the training loss, the better the model performs on the provided practice workbook. Combined with the gradient descent method discussed in section 2.1 on how models learn, the model updates its parameters based on the training loss.",
        "    ",
        "*   **Validation set**: Simulated exam questions. After the model has learned for a period of time, it will be tested once and generate **validation loss** based on the loss function. Validation loss is used to evaluate the effectiveness of model training. The smaller the validation loss, the better the model performs in the simulated exam.",
        "    ",
        "*   **Test set**: Real exam questions. The accuracy of the model on the test set is used to evaluate the final performance of the model.",
        "",
        "The three states of model training:",
        "",
        "*   **Unchanged or increasing training loss**: This indicates **training failure**. You can think of it as the model not learning anything from the training set (practice workbook), indicating that there is an issue with the model's learning method.",
        "    ",
        "*   **Both training loss and validation loss are decreasing**: This indicates that the model is **underfitting**. You can imagine that the model is making progress on the training set (practice workbook) and its performance on the validation set (simulated exam) is also improving, but there is still more room for improvement. At this point, you should let the model continue learning.",
        "    ",
        "*   **Decreasing training loss but increasing validation loss**: This indicates that the model is **overfitting**. You can think of it as the model simply memorizing the training set (practice workbook). When taking the exam, it struggles with unseen questions. In this scenario, methods to suppress the model‚Äôs tendency to memorize should be applied, such as providing it with 20 more workbooks so that it cannot remember all the questions and is forced to learn the underlying patterns in the questions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23363db8",
      "metadata": {},
      "source": [
        "### 3.2 Baseline Model Examination",
        "",
        "Before starting the model fine-tuning, let's first take a look at how the baseline model performs on the test set.  ",
        "",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a54a02d5",
      "metadata": {
        "ExecutionIndicator": {
          "show": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import json",
        "from IPython.display import Markdown",
        "",
        "sum, score = 0, 0",
        "for line in open(\"./resources/2_7/test.jsonl\"):",
        "    # Read math questions from the test set",
        "    math_question = json.loads(line)",
        "    query = math_question[\"messages\"][1][\"content\"]",
        "    # Inference using the baseline model",
        "    response, _ = inference(model, template, query)",
        "    # Get the correct answer",
        "    ans = math_question[\"messages\"][2][\"content\"]",
        "    pos = ans.find(\"ans\")",
        "    end_pos = ans[pos:].find('}}')",
        "    ans = ans[pos - 2: end_pos + pos + 2]",
        "    # Format output",
        "    print((\"========================================================================================\"))",
        "    print(query.split(\"#Êï∞Â≠¶È¢ò#\\n\")[1])",
        "    print(\"The correct answer is: \" + ans)",
        "    print(\"-----------Model Response----------------\")",
        "    display(Latex(response))",
        "    print(\"-----------End of Response----------------\")",
        "    # Calculate model score",
        "    if ans in response or ans[6:-2] in response:",
        "        score += 1",
        "        print(\"Model answered correctly\")",
        "    else: print(\"Model answered incorrectly\")",
        "    sum += 1",
        "# Summary",
        "display(Markdown(\"Model scored: **\" + str(int(100*score/sum)) + \"** points in the exam\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4baa331f",
      "metadata": {},
      "source": [
        "The baseline model often abandons reasoning midway during exams, struggling to provide correct answers. This performance not only confirms that the question difficulty exceeds its processing capability but also reveals the fundamental reason why prompt engineering is ineffective ‚Äî the model itself lacks the necessary problem-solving ability. Fine-tuning the model is the only solution.  ",
        "",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbf59e5e",
      "metadata": {},
      "source": [
        "### 3.3 Model Fine-tuning",
        "",
        "Here, we use the [ms-swift](https://github.com/modelscope/ms-swift/tree/main) (Modelscope Scalable lightWeight Infrastructure for Fine-Tuning) framework, an open-source framework specifically developed by Alibaba's ModelScope community for model training. This framework supports the training (pre-training, fine-tuning, alignment), inference, evaluation, and deployment of over 350 large language models (LLMs) and more than 90 multi-modal large models (MLLMs).",
        "",
        "Moreover, the ms-swift framework is very convenient to use. Each time it calculates the validation loss (evaluation loss), the framework automatically saves the current model parameters (model_checkpoint) of the training phase and automatically saves the parameters with the smallest validation loss at the end of the training, which corresponds to the (best_model_checkpoint) in the figure below.",
        "",
        "<div style=\"text-align: center;\">",
        "<img src=\"https://img.alicdn.com/imgextra/i3/O1CN01vxMp4Z1PgVgC1ikNd_!!6000000001870-2-tps-1331-88.png\" style=\"width: 70%;display: block; margin-left: auto; margin-right: auto\"/>",
        "</div>",
        "",
        "In the subsequent multiple experiments, we will focus on adjusting three parameters: learning_rate, LoRA (lora_rank), and the number of dataset training epochs (num_train_epochs). We will also replace the dataset to demonstrate how to perform LoRA fine-tuning. Adjustments to other parameters are made to facilitate the presentation of experimental results, such as increasing the batch size (batch_size) to shorten training time, which you do not need to pay too much attention to.",
        "",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a91a945d",
      "metadata": {},
      "source": [
        "#### 3.3.1 First Experiment (Takes 1 minute)",
        "",
        "In the initial experiment, it is recommended that you first fine-tuning according to the following parameter settings, and use a dataset of 100 problem solutions generated by DeepSeek-R1 for training, so as to improve the training effect through parameter optimization in subsequent experimental stages:",
        "",
        "| Parameter | Parameter Value |",
        "| --- | --- |",
        "| learning rate (learning_rate) | 0.1 |",
        "| LoRA Rank (lora_rank) | 4 |",
        "| Number of Training Epochs (num_train_epochs) | 1 |",
        "| Dataset Location (dataset) | Dataset Location: current directory/resources/2_4/train_100.jsonl |",
        "| You can adjust all parameters freely, but due to display effects and memory constraints, there are the following limitations: | batch_size <= 16 (memory constraint) <br>max_length <= 512 (maximum length of each training data, memory constraint) <br>lora_rank <= 64 (LoRA rank, memory constraint) <br>eval_step <= 20 (for convenience of display) |",
        "",
        "Start the experiment:<br/>",
        "The fine-tuning module of the ms-swift framework uses LoRA fine-tuning by default, so there is no need to explicitly declare the fine-tuning method in the experiment.<br/>",
        "At the same time, the framework will intelligently reduce the actual learning rate during the training process to ensure that the model does not always skip the optimal solution.",
        "",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5988325c",
      "metadata": {
        "ExecutionIndicator": {
          "show": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "%env CUDA_VISIBLE_DEVICES=0",
        "%env LOG_LEVEL=INFO",
        "!swift sft \\",
        "--learning_rate '0.1' \\",
        "--lora_rank 4 \\",
        "--num_train_epochs 1 \\",
        "--dataset './resources/2_7/train_100.jsonl' \\",
        "--batch_size '8' \\",
        "--max_length 512 \\",
        "--eval_step 1 \\",
        "--model_type 'qwen2_5-1_5b-instruct' \\",
        "--model_id_or_path './model'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a52b2e2e",
      "metadata": {},
      "source": [
        "| Training loss image | Evaluation loss image |",
        "| --- | --- |",
        "|<img src=\"https://img.alicdn.com/imgextra/i2/O1CN0122CqML1xiykiTglmo_!!6000000006478-2-tps-667-451.png\" style=\"width: 500px;display: block; margin-left: auto; margin-right: auto\"/> | <img src=\"https://img.alicdn.com/imgextra/i4/O1CN01AxXE0V1JqEORoVBdi_!!6000000001079-2-tps-667-451.png\" style=\"width: 500px;display: block; margin-left: auto; margin-right: auto\"/> |",
        "",
        "| **Observation metrics (training loss, validation loss):** | Training loss increases, validation loss increases |",
        "| --- | --- |",
        "| **Training status:** | **Training failed** |",
        "| **Cause analysis:** | It is highly likely that the learning rate is too high, causing the model parameters to oscillate repeatedly near the optimal solution and fail to find the optimal solution, resulting in training failure.<img src=\"https://img.alicdn.com/imgextra/i1/O1CN01l4leTB1LKI0BcVs16_!!6000000001280-2-tps-1658-1262.png\" style=\"width: 300px;display: block; margin-left: auto; margin-right: auto\"/>|",
        "| **Adjustment logic:** | Significantly reduce the learning rate to $0.00005$, allowing the model to \"learn cautiously\" with smaller steps. |",
        "",
        "#### 3.3.2 Second Experiment (requires 2 minutes)",
        "",
        "<div style=\"width: 30%\">",
        "    ",
        "| Parameter | Old parameter value | New parameter value |",
        "| --- | --- | --- |",
        "| Learning rate (learning_rate) | 0.1 $ $ | 0.00005 |",
        "    ",
        "</div>  ",
        "",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "053c0d3d",
      "metadata": {
        "ExecutionIndicator": {
          "show": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "%env CUDA_VISIBLE_DEVICES=0",
        "%env LOG_LEVEL=INFO",
        "!swift sft \\",
        "--learning_rate '0.00005' \\",
        "--lora_rank 4 \\",
        "--num_train_epochs 1 \\",
        "--dataset './resources/2_7/train_100.jsonl' \\",
        "--batch_size '8' \\",
        "--max_length 512 \\",
        "--eval_step 1 \\",
        "--model_type 'qwen2_5-1_5b-instruct' \\",
        "--model_id_or_path './model'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6af933c4",
      "metadata": {},
      "source": [
        "| Training loss image | Evaluation loss image |",
        "| --- | --- |",
        "|<img src=\"https://img.alicdn.com/imgextra/i3/O1CN01DgtNVX1EDgzHYamOE_!!6000000000318-2-tps-680-451.png\" style=\"width: 500px;display: block; margin-left: auto; margin-right: auto\"/> | <img src=\"https://img.alicdn.com/imgextra/i3/O1CN01621v4k1ErzqC24Z1b_!!6000000000406-2-tps-689-451.png\" style=\"width: 500px;display: block; margin-left: auto; margin-right: auto\"/> |",
        "",
        "| **Observation Metrics (Training Loss, Validation Loss):** | Training loss decreases, validation loss also decreases |",
        "| --- | --- |",
        "| **Training Status:** | **Underfitting** |",
        "| **Cause Analysis:** | Underfitting is a very common phenomenon during training. It indicates that, with the parameters unchanged, simply allowing the model to train longer can lead to successful training. Of course, modifying the parameters can also accelerate the training process. |",
        "| **Adjustment Logic:** | 1. Let the model train longer: Increase the number of dataset learning cycles `epoch` to 50. <br/> 2. Adjust `batch_size` to the maximum value of 16 to speed up model training. |",
        "",
        "#### 3.3.3 Third Experiment (Takes 10 minutes)",
        "",
        "<div style=\"width: 50%\">",
        "",
        "| Parameter | Old Parameter Value | New Parameter Value |",
        "| :--- | :--- | :--- |",
        "| Number of Training Epochs (num_train_epochs) | 1 | 50 |",
        "| batch_size | 8 | 16 |",
        "| eval_step | 1 | 20 (Optimized output display) |",
        "",
        "</div> ",
        "",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "647638fe",
      "metadata": {
        "ExecutionIndicator": {
          "show": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "%env CUDA_VISIBLE_DEVICES=0",
        "%env LOG_LEVEL=INFO",
        "!swift sft \\",
        "--learning_rate '0.00005' \\",
        "--lora_rank 4 \\",
        "--num_train_epochs 50 \\",
        "--dataset './resources/2_7/train_100.jsonl' \\",
        "--batch_size '16' \\",
        "--max_length 512 \\",
        "--eval_step 20 \\",
        "--model_type 'qwen2_5-1_5b-instruct' \\",
        "--model_id_or_path './model'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8933c14b",
      "metadata": {},
      "source": [
        "| Training loss image | Evaluation loss image |",
        "| --- | --- |",
        "|<img src=\"https://img.alicdn.com/imgextra/i4/O1CN01xsw3a31YarKvsEKCR_!!6000000003076-2-tps-671-451.png\" style=\"width: 500px;display: block; margin-left: auto; margin-right: auto\"/> | <img src=\"https://img.alicdn.com/imgextra/i3/O1CN01b2v3fK1jOSNo73Q3y_!!6000000004538-2-tps-680-451.png\" style=\"width: 500px;display: block; margin-left: auto; margin-right: auto\"/> |",
        "",
        "| **Observation Metrics (Training Loss, Validation Loss):** | Training loss decreases, validation loss first decreases then increases |",
        "| --- | --- |",
        "| **Training Status:** | **overfitting** |",
        "| **Cause Analysis:** | overfitting is also a very common phenomenon during training. It indicates that the model is \"memorizing questions\" and not learning the knowledge in the dataset. We can reduce the number of epochs or increase the amount of data to make the model \"forget the questions.\" |",
        "| **Adjustment Logic:** | 1. Reduce the number of epochs to 5. <br/> 2. Expand the number of problem solutions generated by DeepSeek-R1 to 1000 entries. Dataset location: current directory/resources/2_4/train_1k.jsonl <br/> 3. After increasing the amount of data, increase the rank of LoRA to 16 based on previous learning. |",
        "",
        "In general, with the scale of today's large language models (LLMs), fine-tuning requires at least **1000+** high-quality training dataset entries. When below this threshold, the model tends to \"memorize questions\" after a few rounds of training instead of learning the inherent knowledge within the data.",
        "",
        "#### 3.3.4 Fourth Experiment (Expected to take 5 minutes)",
        "",
        "| Parameter | Old Value | New Value |",
        "| --- | --- | --- |",
        "| Change Dataset | 100 entries | 1000+ entries |",
        "| Number of Training Epochs (num_train_epochs) | 50 | 3 |",
        "| LoRA Rank (lora_rank) | 4 | 8 (For reasons why this was increased, refer to the LoRA introduction). | ",
        "",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a77d9f59",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "%env CUDA_VISIBLE_DEVICES=0",
        "%env LOG_LEVEL=INFO",
        "!swift sft \\",
        "--learning_rate '0.00005' \\",
        "--lora_rank 8 \\",
        "--num_train_epochs 3 \\",
        "--dataset './resources/2_7/train_1k.jsonl' \\",
        "--batch_size '16' \\",
        "--max_length 512 \\",
        "--eval_step 20 \\",
        "--model_type 'qwen2_5-1_5b-instruct' \\",
        "--model_id_or_path './model'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f62bd2ca",
      "metadata": {},
      "source": [
        "| Training loss image | Evaluation loss image |",
        "| --- | --- |",
        "|<img src=\"https://img.alicdn.com/imgextra/i3/O1CN01p8rX0d1UAyUOGHeOJ_!!6000000002478-2-tps-671-451.png\" style=\"width: 500px;display: block; margin-left: auto; margin-right: auto\"/> | <img src=\"https://img.alicdn.com/imgextra/i1/O1CN01LjmbJ21P4Uo8ZJyav_!!6000000001787-2-tps-689-451.png\" style=\"width: 500px;display: block; margin-left: auto; margin-right: auto\"/> |",
        "",
        "",
        "| **Observation Metrics (Training Loss, Validation Loss):** | Training loss decreases, validation loss also decreases |",
        "| --- | --- |",
        "| **Training Status:** | **Underfitting** |",
        "| **Reason Analysis:** | Training is almost successful! |",
        "| **Adjustment Logic:** | Let the model train more: Increase the number of dataset learning iterations (epoch) to 15. |",
        "",
        "#### 3.3.5 Fifth Experiment (Requires 20 Minutes)",
        "",
        "| Parameter | Old Parameter Value | New Parameter Value |",
        "| --- | --- | --- |",
        "| Number of Training Epochs (num_train_epochs) | 3 | 15 |",
        "",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbae8bc9",
      "metadata": {
        "ExecutionIndicator": {
          "show": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "%env CUDA_VISIBLE_DEVICES=0",
        "%env LOG_LEVEL=INFO",
        "!swift sft \\",
        "--learning_rate '0.00005' \\",
        "--lora_rank 8 \\",
        "--num_train_epochs 15 \\",
        "--dataset './resources/2_7/train_1k.jsonl' \\",
        "--batch_size '16' \\",
        "--max_length 512 \\",
        "--eval_step 20 \\",
        "--model_type 'qwen2_5-1_5b-instruct' \\",
        "--model_id_or_path './model'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2278eac9",
      "metadata": {},
      "source": [
        "| Training loss image | Evaluation loss image |",
        "| --- | --- |",
        "|<img src=\"https://img.alicdn.com/imgextra/i4/O1CN01hyQhbn1p04zyTeQkv_!!6000000005297-2-tps-671-451.png\" style=\"width: 500px;display: block; margin-left: auto; margin-right: auto\"/> | <img src=\"https://img.alicdn.com/imgextra/i3/O1CN01oy2oZv1r0ejEmpYdQ_!!6000000005569-2-tps-680-451.png\" style=\"width: 500px;display: block; margin-left: auto; margin-right: auto\"/> |",
        "",
        "",
        "| **Observation Metrics (Training Loss, Evaluation Loss):** | Training loss basically does not decrease, evaluation loss also basically does not decrease and even slightly increases |",
        "| --- | --- |",
        "| **Training Status:** | **Training Successful!** |  ",
        "",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecf3c61e",
      "metadata": {},
      "source": [
        "### 3.4 Examination After Successful Fine-Tuning",
        "",
        "After fine-tuning, two `checkpoint` files are generally saved: `best_model_checkpoint` (the model parameters that performed best on the validation set) and `last_model_checkpoint` (the model parameters at the completion of the fine-tuning task).",
        "",
        "Here, replace the `ckpt_dir` in the code below with the address of the `best_model_checkpoint`, and you will be able to call the fine-tuned model.",
        "",
        "First, let's load the model into memory:  ",
        "",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6db20cca",
      "metadata": {
        "ExecutionIndicator": {
          "show": false
        },
        "execution": {
          "iopub.execute_input": "2025-03-05T06:39:42.351491Z",
          "iopub.status.busy": "2025-03-05T06:39:42.351101Z",
          "iopub.status.idle": "2025-03-05T06:39:42.557987Z",
          "shell.execute_reply": "2025-03-05T06:39:42.557464Z",
          "shell.execute_reply.started": "2025-03-05T06:39:42.351463Z"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from swift.tuners import Swift",
        "",
        "# Please modify ckpt_dir to the correct location before running",
        "ckpt_dir = 'output/qwen2_5-1_5b-instruct/vx-xxx/checkpoint-xxx<Please modify to the checkpoint position after lora fine-tuning>'",
        "# Load the model",
        "ft_model = Swift.from_pretrained(model, ckpt_dir, inference_mode=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94883c28",
      "metadata": {},
      "source": [
        "Let's take a look at the performance of the fine-tuned model in the exam.  ",
        "",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bff22696",
      "metadata": {
        "ExecutionIndicator": {
          "show": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "sum, score = 0, 0.0",
        "for line in open(\"./resources/2_7/test.jsonl\"):",
        "    # Read math questions from the test set",
        "    math_question = json.loads(line)",
        "    query = math_question[\"messages\"][1][\"content\"]",
        "    # Use the fine-tuned model for inference",
        "    response, _ = inference(ft_model, template, query)",
        "    # Get the correct answer",
        "    ans = math_question[\"messages\"][2][\"content\"]",
        "    pos = ans.find(\"ans\")",
        "    end_pos = ans[pos:].find('}}')",
        "    ans = ans[pos - 2: end_pos + pos + 2]",
        "    # Organize output",
        "    print((\"========================================================================================\"))",
        "    print(query.split(\"#Math Problem#\\n\")[1])",
        "    print(\"The answer to the question is: \" + ans)",
        "    print(\"-----------Model Response----------------\")",
        "    display(Latex(response))",
        "    print(\"-----------End of Response----------------\")",
        "    # Calculate the model's score",
        "    if ans in response:",
        "        score += 1",
        "        print(\"The model answered correctly\")",
        "    elif ans[6 : -2] in response:",
        "        score += 0.5",
        "        print(\"The model answered correctly but the output format was incorrect\")",
        "    else: print(\"The model answered incorrectly\")",
        "    sum += 1",
        "# Summary",
        "display(Markdown(\"The fine-tuned model scored **\" + str(int(100*score/sum)) + \"** points on the exam\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "960edb37",
      "metadata": {},
      "source": [
        "### 3.5 Parameter Matrix Fusion",
        "",
        "After the model training is completed, there are two ways to use the trained model:",
        "",
        "1. Dynamically load the fine-tuned model at the time of invocation.",
        "",
        "   The low-rank parameter matrix obtained after fine-tuning only occupies 20MB of storage space, which is very convenient for incremental release and propagation. This is also a commonly used method in engineering. It should be noted that if you fine-tune using a specific foundation model, you need to specify the corresponding foundation model when loading.",
        "",
        "   In the previous section, we have already tried this method by specifying `ckpt_dir`.",
        "",
        "2. knowledge fusion the foundation model with the low-rank parameters obtained from fine-tuning to obtain a complete model with updated parameters, and then invoke the fused model.",
        "",
        "Here, we introduce the second method: fusing the \"fine-tuned parameter matrix\" with the \"foundation model parameter matrix\" to store the fine-tuned model parameters as a complete parameter matrix.",
        "",
        "By using the `swift export` method and passing in the path of the fine-tuned model (it is recommended to pass in `best_model_checkpoint`), the fused model can be obtained.",
        "",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01928dad",
      "metadata": {
        "ExecutionIndicator": {
          "show": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "%env LOG_LEVEL=INFO",
        "!swift export \\",
        "--ckpt_dir 'output/qwen2_5-1_5b-instruct/vx-xxx/checkpoint-xxx<Modify to checkpoint location before running>' \\",
        "--merge_lora true"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb781cd7",
      "metadata": {},
      "source": [
        "The log displays the path of the model after fusion. The complete parameter matrix after fusion is stored by default in the `checkpoint` directory. (The complete model parameters for the PAI experimental environment are located at: `output/qwen2_5-1_5b-instruct/vX-XXX/checkpoint-XX-merged`).  ",
        "",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70a31b63",
      "metadata": {},
      "source": [
        "## ‚úÖ Summary of this section",
        "",
        "In this section, we have learned the following:",
        "",
        "* Understanding the core value of model fine-tuning: directly improving the model's reasoning ability in mathematics through targeted data injection, overcoming the limitations of prompt engineering and RAG chatbot.",
        "",
        "* Mastering key training parameters: learning rate controls the magnitude of parameter updates, epoch determines the number of data traversals, batch size affects gradient stability, and the loss function monitors the training status.",
        "",
        "* Understanding the principle of LoRA efficient fine-tuning: reducing memory consumption based on low-rank matrix decomposition (theoretical explanation), and optimizing training effects by adjusting the lora_rank parameter in practice.",
        "",
        "* Completing iterative hyperparameter tuning experiments: solving underfitting and overfitting problems through multiple adjustments of learning rate/data volume/training rounds, ultimately significantly improving the model's problem-solving accuracy.",
        "",
        "Although you can use pre-prepared datasets in this tutorial to experience GPU computing resources for free during fine-tuning, **in actual production, fine-tuning is not simple and requires comprehensive consideration of factors such as computing power costs, data scale, and quality**.",
        "Particularly, attention should be paid to the following aspects:",
        "1. Whether low-cost solutions like prompt engineering and RAG chatbot are sufficient to handle the problem.",
        "2. Whether the amount and quality of data meet the minimum threshold for fine-tuning (at least 1000 high-quality data points).",
        "3. Ensuring that the project budget matches the technical expertise, with acceptable cost-effectiveness.",
        "",
        "### Further Learning",
        "#### Fine-tuning for More Machine Learning Tasks",
        "",
        "* Image classification (e.g., object recognition, medical image diagnosis)",
        "    * Fine-tuning purpose: Optimize feature extraction capabilities for specific image datasets based on pre-trained models (e.g., ResNet, ViT).",
        "    * Key points: Reduce data requirements and leverage the general visual knowledge of pre-trained models to transfer to niche tasks.",
        "",
        "* Object detection (e.g., autonomous driving, security monitoring)",
        "    * Fine-tuning purpose: Adjust the model (e.g., YOLO, Faster R-CNN) for detecting specific objects or scenes.",
        "    * Key points: Optimize the model's sensitivity to target location and category, reducing false positives/missed detections.",
        "",
        "* Machine translation (e.g., domain-specific translation)",
        "    * Fine-tuning purpose: Adapt a general translation model (e.g., mBART, T5) to professional terminology and expression habits.",
        "    * Key points: Address semantic bias issues in vertical domain translations for general models.",
        "",
        "* Recommendation systems (e.g., e-commerce, content platforms)",
        "    * Fine-tuning purpose: Optimize recommendation models (e.g., collaborative filtering, deep ranking models) based on user behavior data.",
        "    * Key points: Balance personalized recommendations with cold-start problems, improving click-through rates/conversion rates.",
        "",
        "#### More Efficient Fine-tuning Methods",
        "",
        "* **Freeze**: This method was one of the earliest PEFT methods. It freezes most of the model's parameters during fine-tuning, training only a small portion of the model‚Äôs parameters (e.g., the last few neural network layers) to quickly adapt to specific task needs. Characteristics:",
        "    * High parameter efficiency (only a small number of parameters are trained).",
        "    * Suitable for scenarios where the task is close to the pre-training objective (e.g., text classification).",
        "    * May not perform well for complex tasks.",
        "<div style=\"text-align: left;\">",
        "<img src=\"https://img.alicdn.com/imgextra/i1/O1CN01X9GOk81sgAEtxflGR_!!6000000005795-2-tps-1340-686.png\" style=\"width: 600px;display: block; margin-left: 60px; margin-right: auto\"/>",
        "</div>",
        "",
        "* **Adapter Tuning**: In the original model architecture, Adapter layers are inserted between certain positions. During fine-tuning, the model‚Äôs original parameters are not trained; only these Adapter layers are trained while the original parameters do not participate in training. Characteristics:",
        "    * Modular design with strong compatibility.",
        "    * Slightly higher parameter count than LoRA but stable performance.",
        "    * Requires modifying the model structure, with additional computation required during inference.",
        "<div style=\"text-align: left;\">",
        "<img src=\"https://img.alicdn.com/imgextra/i2/O1CN016gccCd1CdDpjDxbe9_!!6000000000103-2-tps-1482-1048.png\" style=\"width: 500px;display: block; margin-left: 60px; margin-right: auto\"/>",
        "</div>",
        "",
        "* Prompt Tuning: Indirectly control model behavior by optimizing learnable vectors (Prompt) at the input, freezing model parameters. Characteristics:",
        "    * No need to modify the model structure; only adjust the input.",
        "    * Friendly to generative tasks (e.g., translation, dialogue).",
        "    * Effect depends on prompt design; may be insufficient for complex tasks.",
        "",
        "#### Fine-tuning Dataset Construction Strategy",
        "",
        "Generally speaking, for more complex scenarios, fine-tuning requires at least **1000+ high-quality training dataset samples**. When constructing the dataset, confirm the following points:",
        "",
        "* **Data Quality**: Ensure the dataset is accurate, relevant, and remove ambiguous or incorrect samples.",
        "* **Diversity Coverage**: Include full scenarios, multi-contexts, and professional terminology of the task to avoid single distribution.",
        "* **Class Balance**: If the task involves multiple class scenarios, ensure balanced samples across classes to prevent model bias towards one class.",
        "* **Continuous Iteration**: Fine-tuning is an iterative process; continuously optimize and expand the dataset based on feedback from the model's performance on the validation set.",
        "",
        "If you lack data when fine-tuning a model, it is recommended to enhance the model's capabilities using knowledge base retrieval (e.g., business documents, FAQs).",
        "",
        "> In many complex business scenarios, a combined approach of model optimization and knowledge base retrieval can be adopted.",
        "",
        "You can also use the following strategies to expand the dataset:",
        "",
        "* **Manual Annotation**: Extend typical scenario data by experts.",
        "* **Model Generation**: Simulate business scenario data using large models.",
        "* **External Collection**: Obtain data through web scraping, public datasets, user feedback, etc.",
        "",
        "#### Common Evaluation Metrics for Models",
        "",
        "Evaluation metrics differ significantly for different types of tasks. Below are some typical task evaluation metrics:",
        "",
        "* **Classification Tasks**:",
        "    * Accuracy: The proportion of correct predictions.",
        "    * Precision, Recall, and F1 Score: Used to measure the identification effect of positive classes in binary or multi-class classification problems.",
        "",
        "* **Text Generation Tasks**:",
        "    * BLEU (Bilingual Evaluation Understudy): Mainly used in natural language processing tasks such as machine translation, calculating scores by comparing n-gram overlaps between candidate translations and one or more reference translations.",
        "    * ROUGE (Recall-Oriented Understudy for Gisting Evaluation): Commonly used for automatic summary evaluation, based on n-gram recall, precision, and F-measure.",
        "    * Perplexity: Measures the uncertainty of a probability distribution model predicting a sample; lower is better.",
        "",
        "* **Image Recognition/Object Detection**:",
        "    * Intersection over Union (IoU): The ratio of the intersection area to the union area of two bounding boxes.",
        "    * mAP (mean Average Precision): Widely used in object detection tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e76c79e-cb06-4a10-b6f0-57cc84ed069d",
      "metadata": {},
      "source": [
        "## üî• Post-Class Quiz",
        "",
        "### üîç Single-Choice Question",
        "<details>",
        "<summary style=\"cursor: pointer; padding: 12px; border: 1px solid #dee2e6; border-radius: 6px;\">",
        "<b>Which of the following statements about LoRA is incorrect ‚ùì</b>",
        "",
        "- A. LoRA can effectively reduce the cost of fine-tuning large language models.",
        "- B. LoRA modifies the original weights of the fine-tuned model.",
        "- C. LoRA's implementation is relatively simple and easy to integrate.",
        "- D. The results of LoRA fine-tuning can be easily reverted.",
        "",
        "**[Click to View Answer]**",
        "</summary>",
        "",
        "<div style=\"margin-top: 10px; padding: 15px; border: 1px solid #dee2e6; border-radius: 0 0 6px 6px;\">",
        "",
        "‚úÖ **Reference Answer: B**  ",
        "üìù **Explanation**:  ",
        "- LoRA does not directly modify the original weights but indirectly affects model behavior by adding low-rank matrices. This makes rollback operations simple, as you only need to remove the added low-rank matrices.",
        "",
        "</div>",
        "</details>",
        "",
        "---",
        "",
        "",
        "### üîç Multiple-Choice Question",
        "<details>",
        "<summary style=\"cursor: pointer; padding: 12px; border: 1px solid #dee2e6; border-radius: 6px;\">",
        "<b>You are using Swift to fine-tune a Qwen model and notice a significant upward trend in loss on the validation set. Which of the following actions can help alleviate or resolve this issue ‚ùì</b>",
        "",
        "- A. Increase learning rate",
        "- B. Decrease learning rate",
        "- C. Increase --num_train_epochs",
        "- D. Decrease --num_train_epochs",
        "",
        "**[Click to View Answer]**",
        "</summary>",
        "",
        "<div style=\"margin-top: 10px; padding: 15px;  border: 1px solid #dee2e6; border-radius: 0 0 6px 6px;\">",
        "",
        "‚úÖ **Reference Answer: BD**  ",
        "üìù **Explanation**:  ",
        "- learning_rate: A high learning rate can lead to fast model training but may cause oscillations near the optimal solution, or even non-convergence, resulting in fluctuating loss, which may appear like overfitting. However, this is different from true overfitting.  ",
        "- num_train_epochs: Overfitting may also be caused by too many training epochs. Reducing the number of training epochs can prevent the model from over-learning the training data.",
        "",
        "</div>",
        "</details>  ",
        "",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36cbd470",
      "metadata": {},
      "source": [
        "## ‚úâÔ∏è Evaluation and Feedback",
        "Thank you for studying the Alibaba Cloud Large Language Model ACP Certification course. If you think there are parts of the course that are well-written or need improvement, we look forward to your [evaluation and feedback through this questionnaire](https://survey.aliyun.com/apps/zhiliao/Mo5O9vuie).",
        "",
        "Your criticism and encouragement are our motivation to move forward.  ",
        "",
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}