{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.2 Expanding the Knowledge Scope of the Q&A Bot\n",
        "\n",
        "## üöÑ Preface\n",
        "\n",
        "You have already learned that RAG chatbot is an effective solution for expanding the knowledge scope of large language models (LLMs). In this section, you will learn about the workflow of RAG chatbot and how to create a RAG chatbot application so that it can answer questions based on the company's policy documents.\n",
        "\n",
        "## üçÅ Course Objectives\n",
        "\n",
        "After completing this course, you will be able to:\n",
        "\n",
        "* Understand the workflow of RAG chatbot\n",
        "* Create a RAG chatbot application\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. How RAG Works\n",
        "\n",
        "You might lose points in an exam because you forgot a concept or formula, but if the exam is open-book, you only need to find the most relevant knowledge point and add your understanding to answer the question.\n",
        "\n",
        "The same applies to large language models (LLMs). During training, if the model has not seen certain knowledge points (e.g., your company's policy documents), directly asking it related questions will result in inaccurate answers. However, if relevant knowledge is provided as a reference during content generation, similar to an open-book exam, the quality of the large language models (LLMs)'s responses will significantly improve.\n",
        "\n",
        "Retrieval Augmented Generation (RAG) is a solution that provides reference materials for LLMs. RAG applications typically consist of two parts: **indexing** and **retrieval generation**.\n",
        "\n",
        "### 1.1 Indexing\n",
        "You might mark reference materials before an exam to help you quickly locate relevant information during the test. Similarly, RAG applications often pre-mark references, a process called **indexing**, which includes four steps:<br>\n",
        "1. **Document Parsing**<br>\n",
        "Just as you convert visual information from books into text, RAG applications also need to load and parse knowledge base documents into a textual format that LLMs can understand.\n",
        "2. **Text Chunking**<br>\n",
        "You usually don't flip through an entire book when solving a problem; instead, you look for the most relevant paragraphs. Similarly, RAG applications segment the parsed documents to quickly retrieve the most relevant content later.\n",
        "3. **Text Vectorization**<br>\n",
        "During an open-book exam, you first search for the most relevant paragraphs in the reference materials before answering. In RAG applications, embedding models are used to digitally represent both the paragraphs and the question. After comparing their similarity, the most relevant paragraph is identified. This process is called text vectorization.<br>\n",
        "    > If you're interested in the details of this process, you can explore the extended reading section of this tutorial.\n",
        "4. **Index Storage**<br>\n",
        "Index storage saves the vectorized paragraphs into a vector database, so RAG applications don't need to repeat these steps every time they respond, thus increasing response speed.\n",
        "\n",
        "    <img src=\"https://img.alicdn.com/imgextra/i3/O1CN01h0y0Uy1WH30Q7FRDJ_!!6000000002762-2-tps-1592-503.png\" width=\"800\"><br>\n",
        "\n",
        "    After indexing, RAG applications can retrieve relevant text segments based on user questions.\n",
        "\n",
        "### 1.2 Retrieval Generation\n",
        "Retrieval and generation correspond to the `Retrieval` and `Generation` stages in RAG. **Retrieval** is like searching for materials during an open-book exam, while **generation** involves answering based on the retrieved materials and the question.<br>\n",
        "1. **Retrieval**<br>\n",
        "The retrieval phase recalls the most relevant text segments. The question is vectorized using an embedding model, and semantic similarity is compared with the paragraphs in the vector database to identify the most relevant ones. Retrieval is the most critical part of a RAG application. Imagine finding the wrong material during an exam‚Äîyour answer would be inaccurate. To improve retrieval accuracy, besides using powerful embedding models, techniques like reranking and sentence window retrieval can be applied. You can learn more about these in the next chapter.\n",
        "2. **Generation**<br>\n",
        "After retrieving relevant text segments, the RAG application generates the final prompt by combining the question and the retrieved text segments through a prompt template. The large language models (LLMs) then generates the response, leveraging its summarization abilities rather than relying solely on its internal knowledge.\n",
        "    > A typical prompt template is: `Please answer the user's question based on the following information: {retrieved text segments}. The user's question is: {question}.`\n",
        "\n",
        "    <img src=\"https://img.alicdn.com/imgextra/i1/O1CN01vbkBXC1HQ0SBrC1Ii_!!6000000000751-2-tps-1776-639.png\" width=\"600\"><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Creating a RAG Application\n",
        "\n",
        "Building a RAG application requires implementing the above functionalities, and this process is not easy. However, with LlamaIndex, you can achieve the aforementioned functionalities without writing too much code.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Please confirm your current Python environment  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before running the code in this section of the course, please make sure you have switched to the newly created Python environment, such as the `Python (llm_learn)` environment created in the previous lessons.\n",
        "\n",
        "<img src=\"https://img.alicdn.com/imgextra/i1/O1CN01B9bNMT27MDFvpBmnc_!!6000000007782-2-tps-1944-448.png\" width=\"800\">\n",
        "\n",
        "**Note: In each subsequent lesson, you should check whether you need to manually switch the Notebook environment.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 A Simple RAG chatbot\n",
        "\n",
        "As with the tutorial in the previous section, you need to run the following code to configure the Model Studio API Key into the environment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T09:00:41.030766Z",
          "iopub.status.busy": "2024-11-15T09:00:41.030362Z",
          "iopub.status.idle": "2024-11-15T09:00:41.236899Z",
          "shell.execute_reply": "2024-11-15T09:00:41.236115Z",
          "shell.execute_reply.started": "2024-11-15T09:00:41.030739Z"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your configured API Key is: sk-4b*****\n"
          ]
        }
      ],
      "source": [
        "from config.load_key import load_key\n",
        "import os\n",
        "\n",
        "load_key()\n",
        "# In production environments, do not output the API Key to logs to avoid leakage\n",
        "print(f\"Your configured API Key is: {os.environ[\"DASHSCOPE_API_KEY\"][:5]+\"*\"*5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have prepared some fictional company policy documents in the docs folder, and next you will create a RAG application based on these documents.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio==4.32.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 1)) (4.32.0)\n",
            "Requirement already satisfied: faiss-cpu==1.8.0.post1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 2)) (1.8.0.post1)\n",
            "Requirement already satisfied: dashscope==1.20.14 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 3)) (1.20.14)\n",
            "Requirement already satisfied: openai==1.55.3 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 4)) (1.55.3)\n",
            "Requirement already satisfied: httpx==0.27.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 5)) (0.27.0)\n",
            "Requirement already satisfied: llama-index-vector-stores-faiss==0.1.2 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 6)) (0.1.2)\n",
            "Requirement already satisfied: llama-index-embeddings-dashscope==0.1.4 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 7)) (0.1.4)\n",
            "Requirement already satisfied: llama-index-readers-file==0.1.33 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 8)) (0.1.33)\n",
            "Requirement already satisfied: docx2txt==0.8 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 9)) (0.8)\n",
            "Requirement already satisfied: openpyxl==3.1.5 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 10)) (3.1.5)\n",
            "Requirement already satisfied: llama-index-core==0.10.67 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 11)) (0.10.67)\n",
            "Requirement already satisfied: llama-index-llms-dashscope==0.1.2 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 12)) (0.1.2)\n",
            "Requirement already satisfied: llama-index-readers-dashscope==0.1.2 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 13)) (0.1.2)\n",
            "Requirement already satisfied: llama-index-llms-openai-like==0.1.3 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 14)) (0.1.3)\n",
            "Requirement already satisfied: uvicorn==0.30.6 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 15)) (0.30.6)\n",
            "Requirement already satisfied: fastapi==0.114.1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 16)) (0.114.1)\n",
            "Requirement already satisfied: llama-index-postprocessor-dashscope-rerank-custom==0.1.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 17)) (0.1.0)\n",
            "Requirement already satisfied: simplejson==3.19.3 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 18)) (3.19.3)\n",
            "Requirement already satisfied: matplotlib==3.9.2 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 19)) (3.9.2)\n",
            "Requirement already satisfied: ragas==0.1.9 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 20)) (0.1.9)\n",
            "Requirement already satisfied: langchain_community==0.2.17 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 21)) (0.2.17)\n",
            "Requirement already satisfied: alibabacloud_bailian20231229==1.8.2 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 22)) (1.8.2)\n",
            "Requirement already satisfied: pandas==2.0.3 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 23)) (2.0.3)\n",
            "Requirement already satisfied: alibabacloud_green20220302==2.2.11 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 24)) (2.2.11)\n",
            "Requirement already satisfied: oss2==2.19.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 25)) (2.19.0)\n",
            "Requirement already satisfied: lagent==0.1.2 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 26)) (0.1.2)\n",
            "Requirement already satisfied: mmengine==0.10.3 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 27)) (0.10.3)\n",
            "Requirement already satisfied: ipywidgets==8.1.7 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 28)) (8.1.7)\n",
            "Requirement already satisfied: modelscope in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from -r ../requirements.txt (line 29)) (1.28.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (5.5.0)\n",
            "Requirement already satisfied: ffmpy in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==0.17.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (0.17.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (0.33.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: numpy~=1.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (3.10.15)\n",
            "Requirement already satisfied: packaging in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (2.10.6)\n",
            "Requirement already satisfied: pydub in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (0.12.2)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio==4.32.0->-r ../requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from matplotlib==3.9.2->-r ../requirements.txt (line 19)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from matplotlib==3.9.2->-r ../requirements.txt (line 19)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from matplotlib==3.9.2->-r ../requirements.txt (line 19)) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from matplotlib==3.9.2->-r ../requirements.txt (line 19)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from matplotlib==3.9.2->-r ../requirements.txt (line 19)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from matplotlib==3.9.2->-r ../requirements.txt (line 19)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from pandas==2.0.3->-r ../requirements.txt (line 23)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from pandas==2.0.3->-r ../requirements.txt (line 23)) (2025.2)\n",
            "Requirement already satisfied: aiohttp in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from dashscope==1.20.14->-r ../requirements.txt (line 3)) (3.11.13)\n",
            "Requirement already satisfied: requests in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from dashscope==1.20.14->-r ../requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: websocket-client in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from dashscope==1.20.14->-r ../requirements.txt (line 3)) (1.8.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from openai==1.55.3->-r ../requirements.txt (line 4)) (4.8.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from openai==1.55.3->-r ../requirements.txt (line 4)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from openai==1.55.3->-r ../requirements.txt (line 4)) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from openai==1.55.3->-r ../requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from openai==1.55.3->-r ../requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: certifi in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from httpx==0.27.0->-r ../requirements.txt (line 5)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from httpx==0.27.0->-r ../requirements.txt (line 5)) (1.0.7)\n",
            "Requirement already satisfied: idna in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from httpx==0.27.0->-r ../requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.67->-r ../requirements.txt (line 11)) (2.0.40)\n",
            "Requirement already satisfied: dataclasses-json in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from llama-index-core==0.10.67->-r ../requirements.txt (line 11)) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from llama-index-core==0.10.67->-r ../requirements.txt (line 11)) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from llama-index-core==0.10.67->-r ../requirements.txt (line 11)) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from llama-index-core==0.10.67->-r ../requirements.txt (line 11)) (2025.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from llama-index-core==0.10.67->-r ../requirements.txt (line 11)) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from llama-index-core==0.10.67->-r ../requirements.txt (line 11)) (3.4.2)\n",
            "Requirement already satisfied: nltk!=3.9,>=3.8.1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from llama-index-core==0.10.67->-r ../requirements.txt (line 11)) (3.9.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from llama-index-core==0.10.67->-r ../requirements.txt (line 11)) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from llama-index-core==0.10.67->-r ../requirements.txt (line 11)) (0.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from llama-index-core==0.10.67->-r ../requirements.txt (line 11)) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from llama-index-core==0.10.67->-r ../requirements.txt (line 11)) (1.17.2)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from llama-index-readers-file==0.1.33->-r ../requirements.txt (line 8)) (4.13.3)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from llama-index-readers-file==0.1.33->-r ../requirements.txt (line 8)) (4.3.1)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from llama-index-readers-file==0.1.33->-r ../requirements.txt (line 8)) (0.0.26)\n",
            "Requirement already satisfied: et-xmlfile in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from openpyxl==3.1.5->-r ../requirements.txt (line 10)) (2.0.0)\n",
            "Requirement already satisfied: retrying<2.0.0,>=1.3.4 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from llama-index-readers-dashscope==0.1.2->-r ../requirements.txt (line 13)) (1.4.0)\n",
            "Requirement already satisfied: crcmod>=1.7 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from oss2==2.19.0->-r ../requirements.txt (line 25)) (1.7)\n",
            "Requirement already satisfied: pycryptodome>=3.4.7 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from oss2==2.19.0->-r ../requirements.txt (line 25)) (3.23.0)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from oss2==2.19.0->-r ../requirements.txt (line 25)) (2.16.5)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from oss2==2.19.0->-r ../requirements.txt (line 25)) (2.16.0)\n",
            "Requirement already satisfied: six in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from oss2==2.19.0->-r ../requirements.txt (line 25)) (1.17.0)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from llama-index-llms-openai-like==0.1.3->-r ../requirements.txt (line 14)) (0.1.31)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from llama-index-llms-openai-like==0.1.3->-r ../requirements.txt (line 14)) (4.52.3)\n",
            "Requirement already satisfied: click>=7.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from uvicorn==0.30.6->-r ../requirements.txt (line 15)) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from uvicorn==0.30.6->-r ../requirements.txt (line 15)) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from fastapi==0.114.1->-r ../requirements.txt (line 16)) (0.38.6)\n",
            "Requirement already satisfied: datasets in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ragas==0.1.9->-r ../requirements.txt (line 20)) (3.6.0)\n",
            "Requirement already satisfied: langchain in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ragas==0.1.9->-r ../requirements.txt (line 20)) (0.2.17)\n",
            "Requirement already satisfied: langchain-core in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ragas==0.1.9->-r ../requirements.txt (line 20)) (0.2.43)\n",
            "Requirement already satisfied: langchain-openai in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ragas==0.1.9->-r ../requirements.txt (line 20)) (0.1.25)\n",
            "Requirement already satisfied: pysbd>=0.3.4 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ragas==0.1.9->-r ../requirements.txt (line 20)) (0.3.4)\n",
            "Requirement already satisfied: appdirs in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ragas==0.1.9->-r ../requirements.txt (line 20)) (1.4.4)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from langchain_community==0.2.17->-r ../requirements.txt (line 21)) (0.1.147)\n",
            "Requirement already satisfied: alibabacloud-endpoint-util<1.0.0,>=0.0.3 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from alibabacloud_bailian20231229==1.8.2->-r ../requirements.txt (line 22)) (0.0.4)\n",
            "Requirement already satisfied: alibabacloud-openapi-util<1.0.0,>=0.2.1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from alibabacloud_bailian20231229==1.8.2->-r ../requirements.txt (line 22)) (0.2.2)\n",
            "Requirement already satisfied: alibabacloud-tea-openapi<1.0.0,>=0.3.11 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from alibabacloud_bailian20231229==1.8.2->-r ../requirements.txt (line 22)) (0.3.16)\n",
            "Requirement already satisfied: alibabacloud-tea-util<1.0.0,>=0.3.13 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from alibabacloud_bailian20231229==1.8.2->-r ../requirements.txt (line 22)) (0.3.13)\n",
            "Requirement already satisfied: func-timeout in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from lagent==0.1.2->-r ../requirements.txt (line 26)) (4.3.5)\n",
            "Requirement already satisfied: jsonschema in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from lagent==0.1.2->-r ../requirements.txt (line 26)) (4.23.0)\n",
            "Requirement already satisfied: addict in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from mmengine==0.10.3->-r ../requirements.txt (line 27)) (2.4.0)\n",
            "Requirement already satisfied: rich in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from mmengine==0.10.3->-r ../requirements.txt (line 27)) (13.9.4)\n",
            "Requirement already satisfied: termcolor in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from mmengine==0.10.3->-r ../requirements.txt (line 27)) (3.1.0)\n",
            "Requirement already satisfied: yapf in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from mmengine==0.10.3->-r ../requirements.txt (line 27)) (0.43.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from mmengine==0.10.3->-r ../requirements.txt (line 27)) (4.11.0.86)\n",
            "Requirement already satisfied: comm>=0.1.3 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (9.0.2)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (5.14.3)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (3.0.15)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from gradio-client==0.17.0->gradio==4.32.0->-r ../requirements.txt (line 1)) (11.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from aiohttp->dashscope==1.20.14->-r ../requirements.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from aiohttp->dashscope==1.20.14->-r ../requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from aiohttp->dashscope==1.20.14->-r ../requirements.txt (line 3)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from aiohttp->dashscope==1.20.14->-r ../requirements.txt (line 3)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from aiohttp->dashscope==1.20.14->-r ../requirements.txt (line 3)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from aiohttp->dashscope==1.20.14->-r ../requirements.txt (line 3)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from aiohttp->dashscope==1.20.14->-r ../requirements.txt (line 3)) (1.18.3)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from alibabacloud-openapi-util<1.0.0,>=0.2.1->alibabacloud_bailian20231229==1.8.2->-r ../requirements.txt (line 22)) (44.0.2)\n",
            "Requirement already satisfied: alibabacloud_credentials<2.0.0,>=1.0.2 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from alibabacloud-tea-openapi<1.0.0,>=0.3.11->alibabacloud_bailian20231229==1.8.2->-r ../requirements.txt (line 22)) (1.0.2)\n",
            "Requirement already satisfied: alibabacloud_gateway_spi<1.0.0,>=0.0.2 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from alibabacloud-tea-openapi<1.0.0,>=0.3.11->alibabacloud_bailian20231229==1.8.2->-r ../requirements.txt (line 22)) (0.0.3)\n",
            "Requirement already satisfied: alibabacloud_tea_xml<1.0.0,>=0.0.2 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from alibabacloud-tea-openapi<1.0.0,>=0.3.11->alibabacloud_bailian20231229==1.8.2->-r ../requirements.txt (line 22)) (0.0.3)\n",
            "Requirement already satisfied: alibabacloud-tea>=0.4.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from alibabacloud_credentials<2.0.0,>=1.0.2->alibabacloud-tea-openapi<1.0.0,>=0.3.11->alibabacloud_bailian20231229==1.8.2->-r ../requirements.txt (line 22)) (0.4.3)\n",
            "Requirement already satisfied: alibabacloud_credentials_api<2.0.0,>=1.0.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from alibabacloud_credentials<2.0.0,>=1.0.2->alibabacloud-tea-openapi<1.0.0,>=0.3.11->alibabacloud_bailian20231229==1.8.2->-r ../requirements.txt (line 22)) (1.0.0)\n",
            "Requirement already satisfied: APScheduler<4.0.0,>=3.10.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from alibabacloud_credentials<2.0.0,>=1.0.2->alibabacloud-tea-openapi<1.0.0,>=0.3.11->alibabacloud_bailian20231229==1.8.2->-r ../requirements.txt (line 22)) (3.11.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from altair<6.0,>=4.2.0->gradio==4.32.0->-r ../requirements.txt (line 1)) (1.46.0)\n",
            "Requirement already satisfied: tzlocal>=3.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from APScheduler<4.0.0,>=3.10.0->alibabacloud_credentials<2.0.0,>=1.0.2->alibabacloud-tea-openapi<1.0.0,>=0.3.11->alibabacloud_bailian20231229==1.8.2->-r ../requirements.txt (line 22)) (5.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file==0.1.33->-r ../requirements.txt (line 8)) (2.6)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from dataclasses-json->llama-index-core==0.10.67->-r ../requirements.txt (line 11)) (3.26.1)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from langchain->ragas==0.1.9->-r ../requirements.txt (line 20)) (0.2.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from langchain-core->ragas==0.1.9->-r ../requirements.txt (line 20)) (1.33)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas==0.1.9->-r ../requirements.txt (line 20)) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain_community==0.2.17->-r ../requirements.txt (line 21)) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from pydantic>=2.0->gradio==4.32.0->-r ../requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from pydantic>=2.0->gradio==4.32.0->-r ../requirements.txt (line 1)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from requests->dashscope==1.20.14->-r ../requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: filelock in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like==0.1.3->-r ../requirements.txt (line 14)) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like==0.1.3->-r ../requirements.txt (line 14)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like==0.1.3->-r ../requirements.txt (line 14)) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like==0.1.3->-r ../requirements.txt (line 14)) (0.5.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from huggingface-hub>=0.19.3->gradio==4.32.0->-r ../requirements.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio==4.32.0->-r ../requirements.txt (line 1)) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.67->-r ../requirements.txt (line 11)) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from modelscope->-r ../requirements.txt (line 29)) (76.0.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2==2.19.0->-r ../requirements.txt (line 25)) (0.10.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from cryptography>=3.0.0->alibabacloud-openapi-util<1.0.0,>=0.2.1->alibabacloud_bailian20231229==1.8.2->-r ../requirements.txt (line 22)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=3.0.0->alibabacloud-openapi-util<1.0.0,>=0.2.1->alibabacloud_bailian20231229==1.8.2->-r ../requirements.txt (line 22)) (2.22)\n",
            "Requirement already satisfied: decorator in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (3.0.50)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (2.19.1)\n",
            "Requirement already satisfied: stack_data in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (0.6.3)\n",
            "Requirement already satisfied: wcwidth in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (0.8.4)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from jsonschema->lagent==0.1.2->-r ../requirements.txt (line 26)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from jsonschema->lagent==0.1.2->-r ../requirements.txt (line 26)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from jsonschema->lagent==0.1.2->-r ../requirements.txt (line 26)) (0.23.1)\n",
            "Requirement already satisfied: joblib in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core==0.10.67->-r ../requirements.txt (line 11)) (1.4.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (0.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from rich->mmengine==0.10.3->-r ../requirements.txt (line 27)) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->mmengine==0.10.3->-r ../requirements.txt (line 27)) (0.1.2)\n",
            "Requirement already satisfied: greenlet>=1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.67->-r ../requirements.txt (line 11)) (3.1.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from datasets->ragas==0.1.9->-r ../requirements.txt (line 20)) (20.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from datasets->ragas==0.1.9->-r ../requirements.txt (line 20)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from datasets->ragas==0.1.9->-r ../requirements.txt (line 20)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from datasets->ragas==0.1.9->-r ../requirements.txt (line 20)) (0.70.16)\n",
            "Requirement already satisfied: executing>=1.2.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets==8.1.7->-r ../requirements.txt (line 28)) (0.2.3)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /Users/kchen/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from yapf->mmengine==0.10.3->-r ../requirements.txt (line 27)) (4.3.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r ../requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T09:00:43.822829Z",
          "iopub.status.busy": "2024-11-15T09:00:43.822278Z",
          "iopub.status.idle": "2024-11-15T09:00:58.744414Z",
          "shell.execute_reply": "2024-11-15T09:00:58.743812Z",
          "shell.execute_reply.started": "2024-11-15T09:00:43.822800Z"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsing files...\n",
            "Creating index...\n",
            "Creating query engine...\n",
            "Generating response...\n",
            "The answer is:\n",
            "For project management, your company should consider using tools such as Jira or Trello. These tools help in organizing tasks, tracking progress, and ensuring that projects adhere to the set timelines and requirements. Additionally, they facilitate better communication and collaboration among team members."
          ]
        }
      ],
      "source": [
        "# Import dependencies\n",
        "from llama_index.embeddings.dashscope import DashScopeEmbedding, DashScopeTextEmbeddingModels\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
        "from llama_index.llms.openai_like import OpenAILike\n",
        "\n",
        "# These two lines of code are used to suppress WARNING messages to avoid interference with reading and learning. It is recommended to set the log level as needed in a production environment.\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "print(\"Parsing files...\")\n",
        "# LlamaIndex provides the SimpleDirectoryReader method, which can directly load files from a specified folder into document objects, corresponding to the parsing process.\n",
        "documents = SimpleDirectoryReader('./docs').load_data()\n",
        "\n",
        "print(\"Creating index...\")\n",
        "# The from_documents method includes slicing and index creation steps.\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    # Specify embedding model\n",
        "    embed_model=DashScopeEmbedding(\n",
        "        # You can also use other embedding models provided by Alibaba Cloud: https://help.aliyun.com/zh/model-studio/getting-started/models#3383780daf8hw\n",
        "        model_name=DashScopeTextEmbeddingModels.TEXT_EMBEDDING_V2\n",
        "    ))\n",
        "print(\"Creating query engine...\")\n",
        "query_engine = index.as_query_engine(\n",
        "    # Set to streaming output\n",
        "    streaming=True,\n",
        "    # Here we use the qwen-plus-0919 model. You can also use other Qwen text generation models provided by Alibaba Cloud: https://help.aliyun.com/zh/model-studio/getting-started/models#9f8890ce29g5u\n",
        "    llm=OpenAILike(\n",
        "        model=\"qwen-plus-0919\",\n",
        "        api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
        "        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
        "        is_chat_model=True\n",
        "        ))\n",
        "print(\"Generating response...\")\n",
        "streaming_response = query_engine.query('What tools should our company use for project management?')\n",
        "print(\"The answer is:\")\n",
        "# Use streaming output\n",
        "streaming_response.print_response_stream()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Saving and Loading Index\n",
        "You may find that creating an index takes a relatively long time. If you can save the index locally and load it directly when needed, instead of rebuilding the index, this can significantly improve the response speed. LlamaIndex provides an easy-to-implement method for saving and loading indexes.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T09:00:59.966266Z",
          "iopub.status.busy": "2024-11-15T09:00:59.965889Z",
          "iopub.status.idle": "2024-11-15T09:01:00.240477Z",
          "shell.execute_reply": "2024-11-15T09:01:00.239682Z",
          "shell.execute_reply.started": "2024-11-15T09:00:59.966241Z"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index files saved to knowledge_base/test\n"
          ]
        }
      ],
      "source": [
        "# Save the index as a local file\n",
        "index.storage_context.persist(\"knowledge_base/test\")\n",
        "print(\"Index files saved to knowledge_base/test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T09:01:02.142167Z",
          "iopub.status.busy": "2024-11-15T09:01:02.141798Z",
          "iopub.status.idle": "2024-11-15T09:01:02.675970Z",
          "shell.execute_reply": "2024-11-15T09:01:02.675221Z",
          "shell.execute_reply.started": "2024-11-15T09:01:02.142142Z"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded index from knowledge_base/test path\n"
          ]
        }
      ],
      "source": [
        "# Load the local index file as an index\n",
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "storage_context = StorageContext.from_defaults(persist_dir=\"knowledge_base/test\")\n",
        "index = load_index_from_storage(storage_context, embed_model=DashScopeEmbedding(\n",
        "        model_name=DashScopeTextEmbeddingModels.TEXT_EMBEDDING_V2\n",
        "    ))\n",
        "print(\"Successfully loaded index from knowledge_base/test path\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After loading the index locally, you can test it again by asking questions to see if it works properly.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T09:01:11.982327Z",
          "iopub.status.busy": "2024-11-15T09:01:11.981943Z",
          "iopub.status.idle": "2024-11-15T09:01:14.921721Z",
          "shell.execute_reply": "2024-11-15T09:01:14.921129Z",
          "shell.execute_reply.started": "2024-11-15T09:01:11.982304Z"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating the query engine...\n",
            "Generating response...\n",
            "The answer is:\n",
            "For project management, your company should consider using tools such as Jira or Trello. These tools help in organizing tasks, tracking progress, and ensuring that projects adhere to the set timelines and requirements. Additionally, they facilitate better collaboration among team members and stakeholders."
          ]
        }
      ],
      "source": [
        "print(\"Creating the query engine...\")\n",
        "query_engine = index.as_query_engine(\n",
        "    # Set to streaming output\n",
        "    streaming=True,\n",
        "    # Use the qwen-plus-0919 model here. You can also use other text generation models provided by Alibaba Cloud: https://help.aliyun.com/zh/model-studio/getting-started/models#9f8890ce29g5u\n",
        "    llm=OpenAILike(\n",
        "        model=\"qwen-plus-0919\",\n",
        "        api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
        "        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
        "        is_chat_model=True\n",
        "        ))\n",
        "print(\"Generating response...\")\n",
        "streaming_response = query_engine.query('What tools should our company use for project management?')\n",
        "print(\"The answer is:\")\n",
        "streaming_response.print_response_stream()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can encapsulate the above code so that it can be quickly reused in subsequent iterations.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T09:01:16.991663Z",
          "iopub.status.busy": "2024-11-15T09:01:16.991276Z",
          "iopub.status.idle": "2024-11-15T09:01:20.492123Z",
          "shell.execute_reply": "2024-11-15T09:01:20.491499Z",
          "shell.execute_reply.started": "2024-11-15T09:01:16.991640Z"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For project management, your company should consider using tools such as Jira or Trello. These tools help in organizing tasks, tracking progress, and ensuring that projects adhere to the set timelines and requirements. Additionally, they facilitate better communication and collaboration among team members."
          ]
        }
      ],
      "source": [
        "from chatbot import rag\n",
        "\n",
        "# The citations have been indexed in previous steps, so the index can be loaded directly here. If you need to rebuild the index, you can add a line of code: rag.indexing()\n",
        "index = rag.load_index(persist_path='./knowledge_base/test')\n",
        "query_engine = rag.create_query_engine(index=index)\n",
        "\n",
        "rag.ask('What tools should our company use for project management?', query_engine=query_engine)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Multi-round Conversation\n",
        "The multi-round conversation in RAG is slightly different from the mechanism of directly initiating multi-round conversations with large language models. From the tutorial in section 2.1, you have learned that multi-round conversations allow LLMs to refer to historical dialogue information. The method is to add historical dialogue information to the messages list.\n",
        "\n",
        "During the retrieval phase in RAG applications, the system usually compares the semantic similarity between the user's input and text segments. However, directly comparing the user's input with text segments may lose historical dialogue information, leading to inaccurate retrieval results.\n",
        "\n",
        "Suppose a user asks \"Where is Zhang San's workstation?\" in the first round of dialogue, and then asks \"Who is his supervisor?\" in the second round. If the question in the second round is directly compared with text segments for similarity, the retrieval system will not know who \"he\" refers to, thus likely retrieving incorrect text segments.\n",
        "\n",
        "If both the complete historical dialogue and the question are input into the retrieval system, due to the large number of words, the retrieval system may fail to process it (embedding models perform worse on long texts than on short texts). The commonly used solution in the industry is:\n",
        "\n",
        "1. Through the LLM, based on historical dialogue information, query rewriting. The new query will include key information from the historical dialogue.\n",
        "2. Use the new query to follow the original process for retrieval and generation.\n",
        "\n",
        "LlamaIndex provides convenient tools that can quickly implement multi-round conversations in RAG applications.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T09:01:26.566550Z",
          "iopub.status.busy": "2024-11-15T09:01:26.566171Z",
          "iopub.status.idle": "2024-11-15T09:01:33.772277Z",
          "shell.execute_reply": "2024-11-15T09:01:33.771645Z",
          "shell.execute_reply.started": "2024-11-15T09:01:26.566525Z"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Querying with: What are the core responsibilities of the subtypes of content development engineers?\n",
            "The core responsibilities of content development engineers involve combining educational theory with technical practice to support the growth and development of learners through the creation of high-quality content. This role encompasses several detailed responsibilities:\n",
            "\n",
            "1. Conducting in-depth research on the latest trends in educational technology, learning theories, and market demands. This involves analyzing competitors‚Äô products, evaluating the effectiveness of existing educational resources, and exploring ways to integrate emerging technologies such as artificial intelligence and virtual reality into educational content.\n",
            "\n",
            "2. Designing and developing high-quality educational materials and courses based on research and market feedback. This includes writing syllabi, creating courseware, and designing assessment tools, while ensuring that the content aligns with educational standards and learning objectives to provide a comprehensive learning experience. The content must also be adaptable to various learning styles and levels.\n",
            "\n",
            "3. Continuously optimizing existing educational materials by tracking learner feedback and evaluations, identifying potential issues, and making timely adjustments. Regular updates to the materials are necessary to reflect new research findings, technological advancements, and market changes, ensuring the content remains timely and relevant.\n",
            "\n",
            "4. Collaborating closely with multiple departments, such as instructional designers, educational psychologists, technical teams, and marketing personnel, to ensure the smooth implementation of the content‚Äôs technical processes and effective communication to the target audience. Effective communication and coordination with team members are crucial for joint success."
          ]
        }
      ],
      "source": [
        "from llama_index.core import PromptTemplate\n",
        "from llama_index.core.llms import ChatMessage, MessageRole\n",
        "from llama_index.core.chat_engine import CondenseQuestionChatEngine\n",
        "\n",
        "custom_prompt = PromptTemplate(\n",
        "    \"\"\"\n",
        "Given a conversation (between a human and an assistant) and a follow-up message from the human,\n",
        "rewrite the message as a standalone question that includes all relevant context from the conversation.\n",
        "\n",
        "<Chat History>\n",
        "{chat_history}\n",
        "\n",
        "<Follow-up Message>\n",
        "{question}\n",
        "\n",
        "<Standalone Question>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# Historical conversation information\n",
        "custom_chat_history = [\n",
        "    ChatMessage(role=MessageRole.USER,content=\"What are the subtypes of content development engineers?\"),\n",
        "    ChatMessage(role=MessageRole.ASSISTANT, content=\"Comprehensive technical positions.\"),\n",
        "]\n",
        "\n",
        "query_engine = index.as_query_engine(\n",
        "    # Set to streaming output\n",
        "    streaming=True,\n",
        "    # Use the qwen-plus-0919 model here; you can also use other text generation models provided by Alibaba Cloud: https://help.aliyun.com/zh/model-studio/getting-started/models#9f8890ce29g5u\n",
        "    llm=OpenAILike(\n",
        "        model=\"qwen-plus-0919\",\n",
        "        api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
        "        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
        "        is_chat_model=True\n",
        "        ))\n",
        "chat_engine = CondenseQuestionChatEngine.from_defaults(\n",
        "    query_engine=query_engine,\n",
        "    condense_question_prompt=custom_prompt,\n",
        "    chat_history=custom_chat_history,\n",
        "    llm=OpenAILike(\n",
        "        model=\"qwen-plus-0919\",\n",
        "        api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
        "        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
        "        is_chat_model=True\n",
        "        ),\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "streaming_response = chat_engine.stream_chat(\"What are the core responsibilities?\")\n",
        "for token in streaming_response.response_gen:\n",
        "    print(token, end=\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Although the last question did not mention \"content development engineer,\" the LLM still rewrote the question based on the historical dialogue information as \"What are the core responsibilities of a content development engineer?\" and provided the correct answer.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù3.Summary of this section\n",
        "In this section, you have learned the following content:\n",
        "1. **The working principle of RAG**<br>\n",
        "A complete RAG application usually includes two phases: index building and retrieval generation. Index building consists of four steps: document parsing, text segmentation, text vectorization, and index storage. The retrieval generation phase includes two steps: retrieval and generation. After understanding the working principle of RAG, you can optimize and iterate on the RAG chatbot more effectively.\n",
        "2. **Creating a RAG application**<br>\n",
        "Using the highly integrated tools provided by LlamaIndex, you created a RAG application, and mastered the methods for saving and loading indexes. You also learned how to implement multi-round conversation in a RAG application.\n",
        "\n",
        "Although the RAG chatbot can already answer questions like \"What tools should our company use for project management?\" quite well, its current functionality is still relatively simple. In subsequent tutorials, we will introduce methods to expand the capabilities of the RAG chatbot. The next section will cover how to improve the quality of the RAG chatbot's responses by optimizing prompts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Further Reading\n",
        "\n",
        "#### Text Vectorization\n",
        "Computers cannot directly understand how similar the two sentences \"I like to eat apples\" and \"I love to eat apples\" are, but they can understand the similarity between two vectors of the same dimension (usually measured using cosine similarity). Text vectorization converts natural language into numerical forms that computers can understand through embedding models.\n",
        "\n",
        "The training of embedding models typically includes a phase of **contrastive learning**, where the input data consists of many text pairs (s1, s2) labeled as either related or unrelated. The model's training objective is to make the vector similarity of related text pairs as high as possible and the vector similarity of unrelated text pairs as low as possible.\n",
        "\n",
        "In the **indexing** phase, assuming n chunks [c1, c2, c3, ..., cn] have been obtained through text segmentation, the embedding model will convert these n chunks into vectors: [v1, v2, v3, ..., vn], which are then stored in a vector database.\n",
        "\n",
        "In the **retrieval** phase, assuming the user‚Äôs question is q, the embedding model will convert the question q into a vector vq and find the n most similar vectors to vq in the vector database (this value can be set by you). Through the index relationship between vectors and text segments, the corresponding text segments are retrieved as the search results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî• Post-class Quiz\n",
        "### üîç Multiple Choice Question\n",
        "\n",
        "<details>\n",
        "<summary style=\"cursor: pointer; padding: 12px; border: 1px solid #dee2e6; border-radius: 6px;\">\n",
        "<b>How should retrieval be conducted during multi-turn conversations in RAG applications? ‚ùì</b>\n",
        "\n",
        "- A. Input the complete historical dialogue information during the retrieval phase<br>\n",
        "- B. Rewrite the input question based on historical dialogue information before entering the retrieval phase<br>\n",
        "- C. Input the latest question during the retrieval phase<br>\n",
        "- D. Migrate the text segments recalled from the previous round<br>\n",
        "\n",
        "**[Click to view the answer]**\n",
        "</summary>\n",
        "\n",
        "<div style=\"margin-top: 10px; padding: 15px;  border: 1px solid #dee2e6; border-radius: 0 0 6px 6px;\">\n",
        "\n",
        "‚úÖ **Reference Answer: B**  \n",
        "üìù **Explanation**:  \n",
        "- In multi-turn conversations, directly using the original question (Option C) or the full history (Option A) can lead to retrieval noise or information redundancy.\n",
        "- Option B dynamically rewrites the current question, maintaining conversational coherence while avoiding the outdated text migration issue of Option D, making it the optimal solution balancing efficiency and accuracy.\n",
        "\n",
        "</div>\n",
        "</details>  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Evaluation Feedback\n",
        "We welcome you to participate in the [Alibaba Cloud Large Language Model ACP Course Survey](https://survey.aliyun.com/apps/zhiliao/Mo5O9vuie) to provide feedback on your learning experience and course evaluation.\n",
        "Your criticism and encouragement are our motivation to move forward!  \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
